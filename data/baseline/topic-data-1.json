[
  {
    "topic_group": "political-events",
    "results_against_itself": {
      "train_loss": [
        0.4630344414876567, 0.32129926455241664, 0.3125627519171915,
        0.3285578376165143, 0.31319674132046876
      ],
      "train_acc": [
        90.02587145969498, 92.74691358024691, 92.67883079157589,
        92.61074800290486, 92.7128721859114
      ],
      "test_loss": [
        0.25833370408841544, 0.2522690964596612, 0.25170703594173705,
        0.24976367354393006, 0.25279412397316525
      ],
      "test_acc": [
        93.21266968325791, 93.21266968325791, 93.21266968325791,
        93.21266968325791, 93.21266968325791
      ],
      "test_f1": [
        0.9648711943793911, 0.9648711943793911, 0.9648711943793911,
        0.9648711943793911, 0.9648711943793911
      ],
      "test_brier": [
        0.0668103497638657, 0.06492309812315131, 0.06327244740384017,
        0.06381218549626382, 0.06528790155651655
      ]
    },
    "results_against_all": [
      {
        "health-economy": [
          0.30443059239875186, 92.85714285714286, 0.962962962962963,
          0.07553106946607685
        ]
      },
      {
        "crime-legal": [
          0.29566852039336655, 92.85714285714286, 0.962962962962963,
          0.0759736711496206
        ]
      },
      {
        "disasters-accidents": [
          0.3124387759478792, 92.85714285714286, 0.962962962962963,
          0.07774557212222054
        ]
      },
      {
        "social-cultural-tech": [
          0.30049273696920226, 92.85714285714286, 0.962962962962963,
          0.07592518528610857
        ]
      }
    ]
  },
  {
    "topic_group": "health-economy",
    "results_against_itself": {
      "train_loss": [
        0.5021200134958091, 0.2683028083686766, 0.2514939855195974,
        0.25238132986583206, 0.23944165302734627
      ],
      "train_acc": [
        84.28480475382004, 93.32820458404075, 93.32820458404075,
        93.33085738539899, 93.33085738539899
      ],
      "test_loss": [
        0.3135574339505504, 0.28264081653426676, 0.2908771647249951,
        0.2814125521656345, 0.271410956102259
      ],
      "test_acc": [
        91.74664107485604, 91.74664107485604, 91.74664107485604,
        91.74664107485604, 91.74664107485604
      ],
      "test_f1": [
        0.9569569569569569, 0.9569569569569569, 0.9569569569569569,
        0.9569569569569569, 0.9569569569569569
      ],
      "test_brier": [
        0.0756884713857301, 0.07447958726279356, 0.07509715300666445,
        0.07429435836645447, 0.07252737304537556
      ]
    },
    "results_against_all": [
      {
        "political-events": [
          0.37789217034226347, 92.85714285714286, 0.962962962962963,
          0.07264595573158776
        ]
      },
      {
        "crime-legal": [
          0.2899873026435365, 92.85714285714286, 0.962962962962963,
          0.07213864422764861
        ]
      },
      {
        "disasters-accidents": [
          0.3153272861511343, 92.85714285714286, 0.962962962962963,
          0.07336612316231406
        ]
      },
      {
        "social-cultural-tech": [
          0.2983244148984788, 92.85714285714286, 0.962962962962963,
          0.0716933783340189
        ]
      }
    ]
  },
  {
    "topic_group": "crime-legal",
    "results_against_itself": {
      "train_loss": [
        0.37646188218909576, 0.25427070161305276, 0.24523709983710784,
        0.18546520976955633, 0.13996387953050884
      ],
      "train_acc": [
        90.48124315443593, 92.71631982475355, 92.71631982475355,
        92.736856516977, 93.71234939759036
      ],
      "test_loss": [
        0.2514976081955764, 0.24068081782509884, 0.23604612393925586,
        0.14834212491081822, 0.1274033969319943
      ],
      "test_acc": [
        93.20987654320987, 93.20987654320987, 93.20987654320987,
        93.29805996472663, 94.44444444444444
      ],
      "test_f1": [
        0.9648562300319489, 0.9648562300319489, 0.9648562300319489,
        0.9652650822669104, 0.970846830171217
      ],
      "test_brier": [
        0.06338476894474948, 0.06179870128430877, 0.05892912284023793,
        0.045734196656460266, 0.037968486421736544
      ]
    },
    "results_against_all": [
      {
        "political-events": [
          0.23547377738427241, 91.25475285171103, 0.9536023054755044,
          0.06015768060883247
        ]
      },
      {
        "health-economy": [
          0.24064594597809694, 92.62672811059907, 0.9613059250302297,
          0.06052668141691026
        ]
      },
      {
        "disasters-accidents": [
          0.19368719812186938, 91.59226190476191, 0.9555875802436787,
          0.057691907323385604
        ]
      },
      {
        "social-cultural-tech": [
          0.1748186174839262, 92.95774647887323, 0.9629433562731603,
          0.051923845114212414
        ]
      }
    ]
  },
  {
    "topic_group": "disasters-accidents",
    "results_against_itself": {
      "train_loss": [
        0.36022646871677944, 0.24723145813587005, 0.24027920531088046,
        0.22824842658605468, 0.22416938644614112
      ],
      "train_acc": [
        87.88623595505618, 93.04775280898876, 92.89559925093634,
        93.25842696629213, 93.1062734082397
      ],
      "test_loss": [
        0.2979194419948678, 0.27139482235437945, 0.2490383192504707,
        0.2744494910891119, 0.27268633726788194
      ],
      "test_acc": [
        92.56198347107438, 92.56198347107438, 92.56198347107438,
        92.56198347107438, 92.56198347107438
      ],
      "test_f1": [
        0.9613733905579399, 0.9613733905579399, 0.9613733905579399,
        0.9613733905579399, 0.9612068965517241
      ],
      "test_brier": [
        0.06941842418772161, 0.0683191955539966, 0.06333452242501632,
        0.06786368972778113, 0.06852172580545077
      ]
    },
    "results_against_all": [
      {
        "political-events": [
          0.3728084736985379, 89.95111352525801, 0.9467319320472214,
          0.07934344996181539
        ]
      },
      {
        "health-economy": [
          0.3080902330916036, 90.95622119815668, 0.9524098211579267,
          0.07485621573054226
        ]
      },
      {
        "crime-legal": [
          0.28993755888131234, 90.8994708994709, 0.9519284516489658,
          0.07406758604472044
        ]
      },
      {
        "social-cultural-tech": [
          0.291740146687343, 88.98390342052313, 0.9411132024737834,
          0.07772445367287649
        ]
      }
    ]
  },
  {
    "topic_group": "social-cultural-tech",
    "results_against_itself": {
      "train_loss": [
        0.45886496268212795, 0.26724755340679124, 0.25495857339013706,
        0.2512439306486737, 0.24266270344907587
      ],
      "train_acc": [
        84.80113636363636, 93.2528409090909, 93.2528409090909,
        93.17234848484848, 93.2528409090909
      ],
      "test_loss": [
        0.3256038489114297, 0.2685953898257331, 0.2668956947561942,
        0.25911813974380493, 0.23899464877812485
      ],
      "test_acc": [
        92.12730318257957, 92.12730318257957, 92.12730318257957,
        92.12730318257957, 92.12730318257957
      ],
      "test_f1": [
        0.959023539668701, 0.959023539668701, 0.959023539668701,
        0.959023539668701, 0.959023539668701
      ],
      "test_brier": [
        0.07311248496073476, 0.07031654089860713, 0.07039774695947684,
        0.06907999605768507, 0.06509806358909086
      ]
    },
    "results_against_all": [
      {
        "political-events": [
          0.36254259282401924, 92.85714285714286, 0.962962962962963,
          0.07305373104270677
        ]
      },
      {
        "health-economy": [
          0.2994933172044429, 92.85714285714286, 0.962962962962963,
          0.07173422824173725
        ]
      },
      {
        "crime-legal": [
          0.2787753637066158, 92.85714285714286, 0.962962962962963,
          0.07146383083405859
        ]
      },
      {
        "disasters-accidents": [
          0.30381446200171636, 92.85714285714286, 0.962962962962963,
          0.07380519719485448
        ]
      }
    ]
  }
]
