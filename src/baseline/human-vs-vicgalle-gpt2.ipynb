{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm \n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DATA_RAW = '../../data/raw'\n",
    "HUMAN_JSON_PATH = f'{ROOT_DATA_RAW}/human.jsonl'\n",
    "VICGALLE_GPT2_JSON_PATH = f'{ROOT_DATA_RAW}/machines/vicgalle-gpt2-open-instruct-v1.jsonl'\n",
    "BATCH_SIZE = 32\n",
    "LSTM_UNITS = 128\n",
    "LSTM_LAYERS = 5\n",
    "EMBEDDING_SIZE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_df = pd.read_json(path_or_buf=HUMAN_JSON_PATH, lines=True)\n",
    "llm_df = pd.read_json(path_or_buf=VICGALLE_GPT2_JSON_PATH, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Fact check: Biden inauguration impacted by pan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Highlights from Joe Biden's 2021 inauguration\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Biden takes the helm, appeals for unity to tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>'The Hill We Climb': Read Amanda Gorman's inau...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "1  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "2  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "3  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "4  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "\n",
       "                                                text  \n",
       "0  Inaugural Address by President Joseph R. Biden...  \n",
       "1  Fact check: Biden inauguration impacted by pan...  \n",
       "2  Highlights from Joe Biden's 2021 inauguration\\...  \n",
       "3  Biden takes the helm, appeals for unity to tak...  \n",
       "4  'The Hill We Climb': Read Amanda Gorman's inau...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1/news-2021-01-01...</td>\n",
       "      <td>\"America's Future: What Happens to the Constit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1/news-2021-01-01...</td>\n",
       "      <td>President Trump Is Not Present at The 2020 Ina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1/news-2021-01-01...</td>\n",
       "      <td>Trump leaves White House with heightened secur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1/news-2021-01-01...</td>\n",
       "      <td>Joe Biden is the 46th President of the United ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1/news-2021-01-01...</td>\n",
       "      <td>'Amanda Gorman Celebrates New York Times Poet ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0  vicgalle-gpt2-open-instruct-v1/news-2021-01-01...   \n",
       "1  vicgalle-gpt2-open-instruct-v1/news-2021-01-01...   \n",
       "2  vicgalle-gpt2-open-instruct-v1/news-2021-01-01...   \n",
       "3  vicgalle-gpt2-open-instruct-v1/news-2021-01-01...   \n",
       "4  vicgalle-gpt2-open-instruct-v1/news-2021-01-01...   \n",
       "\n",
       "                                                text  \n",
       "0  \"America's Future: What Happens to the Constit...  \n",
       "1  President Trump Is Not Present at The 2020 Ina...  \n",
       "2  Trump leaves White House with heightened secur...  \n",
       "3  Joe Biden is the 46th President of the United ...  \n",
       "4  'Amanda Gorman Celebrates New York Times Poet ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_df['is_llm'] = 0\n",
    "llm_df['is_llm'] = 1\n",
    "\n",
    "human_df.drop(labels=['id'], inplace=True, axis='columns')\n",
    "llm_df.drop(labels=['id'], inplace=True, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_llm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"America's Future: What Happens to the Constit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>President Trump Is Not Present at The 2020 Ina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump leaves White House with heightened secur...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joe Biden is the 46th President of the United ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'Amanda Gorman Celebrates New York Times Poet ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_llm\n",
       "0  \"America's Future: What Happens to the Constit...       1\n",
       "1  President Trump Is Not Present at The 2020 Ina...       1\n",
       "2  Trump leaves White House with heightened secur...       1\n",
       "3  Joe Biden is the 46th President of the United ...       1\n",
       "4  'Amanda Gorman Celebrates New York Times Poet ...       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_llm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fact check: Biden inauguration impacted by pan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Highlights from Joe Biden's 2021 inauguration\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biden takes the helm, appeals for unity to tak...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'The Hill We Climb': Read Amanda Gorman's inau...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_llm\n",
       "0  Inaugural Address by President Joseph R. Biden...       0\n",
       "1  Fact check: Biden inauguration impacted by pan...       0\n",
       "2  Highlights from Joe Biden's 2021 inauguration\\...       0\n",
       "3  Biden takes the helm, appeals for unity to tak...       0\n",
       "4  'The Hill We Climb': Read Amanda Gorman's inau...       0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([human_df, llm_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_llm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fact check: Biden inauguration impacted by pan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Highlights from Joe Biden's 2021 inauguration\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biden takes the helm, appeals for unity to tak...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'The Hill We Climb': Read Amanda Gorman's inau...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_llm\n",
       "0  Inaugural Address by President Joseph R. Biden...       0\n",
       "1  Fact check: Biden inauguration impacted by pan...       0\n",
       "2  Highlights from Joe Biden's 2021 inauguration\\...       0\n",
       "3  Biden takes the helm, appeals for unity to tak...       0\n",
       "4  'The Hill We Climb': Read Amanda Gorman's inau...       0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_llm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>'The Disappearance of Gabby Petito' – A Compre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>Utah State Police Search for Gabby Petito, Tra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>McKenna's Lost Friend: Debunking the Evidence ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>\"Gunshots Found in Florida Nature Preserve: A ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2173</th>\n",
       "      <td>A Very Kind and Sweet Woman in Long Island Sho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  is_llm\n",
       "2169  'The Disappearance of Gabby Petito' – A Compre...       1\n",
       "2170  Utah State Police Search for Gabby Petito, Tra...       1\n",
       "2171  McKenna's Lost Friend: Debunking the Evidence ...       1\n",
       "2172  \"Gunshots Found in Florida Nature Preserve: A ...       1\n",
       "2173  A Very Kind and Sweet Woman in Long Island Sho...       1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\boyan.bogdanov\\.conda\\envs\\llm-detect\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\boyan.bogdanov\\.cache\\huggingface\\hub\\models--distilbert-base-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\boyan.bogdanov\\.conda\\envs\\llm-detect\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "checkpoint = 'distilbert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28996\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (843 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "df['tokenized_text'] = tokenizer(list(df['text'].to_list()))['input_ids']\n",
    "tokenized = tokenizer(list(df['text'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Michael', 'is', 'good', 'Peter', 'is', 'good']\n",
      "[None, 0, 1, 2, None]\n",
      "[[101, 1847, 1110, 1363, 102], [101, 1943, 1110, 1363, 102]]\n",
      "[[1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "test_tokenized = tokenizer(['Michael is good', 'Peter is good'])\n",
    "print(tokenizer.tokenize(['Michael is good', 'Peter is good']))\n",
    "print(test_tokenized.word_ids())\n",
    "print(test_tokenized['input_ids'])\n",
    "print(test_tokenized['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_llm</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 1130, 3984, 13830, 4412, 24930, 18380, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fact check: Biden inauguration impacted by pan...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 143, 11179, 4031, 131, 139, 26859, 20105...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Highlights from Joe Biden's 2021 inauguration\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 1693, 13231, 1121, 2658, 139, 26859, 112...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biden takes the helm, appeals for unity to tak...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 139, 26859, 2274, 1103, 22778, 117, 1599...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'The Hill We Climb': Read Amanda Gorman's inau...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 112, 1109, 2404, 1284, 140, 24891, 1830,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_llm  \\\n",
       "0  Inaugural Address by President Joseph R. Biden...       0   \n",
       "1  Fact check: Biden inauguration impacted by pan...       0   \n",
       "2  Highlights from Joe Biden's 2021 inauguration\\...       0   \n",
       "3  Biden takes the helm, appeals for unity to tak...       0   \n",
       "4  'The Hill We Climb': Read Amanda Gorman's inau...       0   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [101, 1130, 3984, 13830, 4412, 24930, 18380, 1...  \n",
       "1  [101, 143, 11179, 4031, 131, 139, 26859, 20105...  \n",
       "2  [101, 1693, 13231, 1121, 2658, 139, 26859, 112...  \n",
       "3  [101, 139, 26859, 2274, 1103, 22778, 117, 1599...  \n",
       "4  [101, 112, 1109, 2404, 1284, 140, 24891, 1830,...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, layers_num, output_size=1, dropout=0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers_num = layers_num\n",
    "        self.output_size= output_size\n",
    "        self.dropout = dropout\n",
    "        self.device = device\n",
    "\n",
    "        self.embed = nn.Embedding(self.vocab_size, self.embedding_size, device=self.device)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=self.layers_num,\n",
    "            batch_first=True,\n",
    "            dropout=self.dropout,\n",
    "            device=self.device        \n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(\n",
    "            self.hidden_size,\n",
    "            self.output_size\n",
    "        )\n",
    "\n",
    "    def forward(self, X, lengths):\n",
    "        embeddings = self.embed(X)\n",
    "        padded_input = nn.utils.rnn.pack_padded_sequence(embeddings, lengths, batch_first=True)\n",
    "\n",
    "        seq_output, (h_n, c_n) = self.lstm(padded_input)\n",
    "        seq_output, _ = nn.utils.rnn.pad_packed_sequence(seq_output, batch_first=True)\n",
    "        out = seq_output.sum(dim=1).div(lengths.float().unsqueeze(dim=1))\n",
    "        logits = self.fc(out)\n",
    "        return logits\n",
    "    \n",
    "model = RNN(tokenizer.vocab_size, EMBEDDING_SIZE, LSTM_UNITS, LSTM_LAYERS)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            self.X[index],\n",
    "            self.y[index]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextDataset(df['tokenized_text'], df['is_llm'])\n",
    "test_set_size = int(dataset.__len__() * 0.2)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [\n",
    "    dataset.__len__() - test_set_size,\n",
    "    test_set_size,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [3:13:57<00:00, 211.59s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 mean cost=0.560837176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:18<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test: 0.16191352345906163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 4/55 [05:16<1:07:13, 79.09s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m       \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy on test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevaluate(model,\u001b[38;5;250m \u001b[39mtest_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m costs\n\u001b[1;32m---> 53\u001b[0m costs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimization Finished!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[29], line 43\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, dataset, test_dataset, max_epochs)\u001b[0m\n\u001b[0;32m     40\u001b[0m bce \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss()\n\u001b[0;32m     41\u001b[0m cost \u001b[38;5;241m=\u001b[39m bce(y_hat, y)\n\u001b[1;32m---> 43\u001b[0m \u001b[43mcost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     46\u001b[0m costs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(cost\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Users\\boyan.bogdanov\\.conda\\envs\\llm-detect\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\boyan.bogdanov\\.conda\\envs\\llm-detect\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "  # We want to sort the batch by seq length, \n",
    "  # in order to make the computation more efficient\n",
    "  batch = sorted(batch, key=lambda x: len(x[0]), reverse=True)\n",
    "  \n",
    "  inputs = [torch.LongTensor(x[0]).to(device) for x in batch]\n",
    "  padded_input = nn.utils.rnn.pad_sequence(inputs, batch_first=True)\n",
    "  lengths = torch.LongTensor([len(x[0]) for x in batch]).to(device)\n",
    "  y = torch.FloatTensor(np.array([x[1] for x in batch])).reshape(-1, 1).to(device)\n",
    "  return padded_input, lengths, y\n",
    "\n",
    "def evaluate(model, test_dataset):\n",
    "  model.eval()\n",
    "  correct_pred = 0\n",
    "  dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                      shuffle=False, drop_last=False,\n",
    "                        collate_fn=collate_fn\n",
    "                      )\n",
    "  \n",
    "  for x, l, y in tqdm(dataloader, total=len(dataloader)):\n",
    "    with torch.no_grad():\n",
    "      y_hat = model(x, l)\n",
    "      correct_pred += torch.eq(torch.sigmoid(y_hat).round(), y).sum().item()\n",
    "      \n",
    "  return correct_pred / len(dataset)\n",
    "\n",
    "def train(model, optimizer, dataset, test_dataset, max_epochs=2):\n",
    "  costs = []\n",
    "  for epoch in range(1, max_epochs+1):\n",
    "    model.train()\n",
    "    costs.append([])\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, drop_last=False,\n",
    "                        collate_fn=collate_fn\n",
    "                        )\n",
    "    for x, l, y in tqdm(dataloader, total=len(dataloader)):\n",
    "      optimizer.zero_grad()\n",
    "      y_hat = model(x, l)\n",
    "\n",
    "      bce = nn.BCEWithLogitsLoss()\n",
    "      cost = bce(y_hat, y)\n",
    "\n",
    "      cost.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      costs[-1].append(cost.item())\n",
    "    # Display logs per each DISPLAY_STEP\n",
    "    if (epoch) % 1 == 0:\n",
    "      print(\"Epoch: {:04d} mean cost={:.9f}\".format(epoch, np.mean(costs[-1])))\n",
    "      print(f\"Accuracy on test: {evaluate(model, test_dataset)}\")\n",
    "  return costs\n",
    "\n",
    "costs = train(model, optimizer, train_dataset, test_dataset, max_epochs=2)\n",
    "print (\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(chain(*costs), columns=['loss']).rolling(10).mean().plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-detect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
