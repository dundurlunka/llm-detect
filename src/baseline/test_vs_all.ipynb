{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from timeit import default_timer as timer\n",
    "from os import walk\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_curve, auc, brier_score_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DATA = '../../data'\n",
    "HUMAN_JSON_FILE_NAME = 'human.jsonl'\n",
    "HUMAN_JSON_PATH = f'{ROOT_DATA}/raw/{HUMAN_JSON_FILE_NAME}'\n",
    "MODELS_JSON_FOLDER_PATH = f'{ROOT_DATA}/raw/machines'\n",
    "BASELINE_MODELS_FOLDER_PATH = f'{ROOT_DATA}/baseline/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "LSTM_UNITS = 256\n",
    "LSTM_LAYERS = 5\n",
    "EMBEDDING_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SET_FRACTION = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(path_or_buf=HUMAN_JSON_PATH, lines=True)\n",
    "df['text_index'] = df.index\n",
    "df['is_llm'] = 0\n",
    "df['dataset_name'] = Path(HUMAN_JSON_FILE_NAME).stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path, dir_names, file_names = next(walk(MODELS_JSON_FOLDER_PATH))\n",
    "\n",
    "for file_name in file_names:\n",
    "    temp_df = pd.read_json(path_or_buf=f'{MODELS_JSON_FOLDER_PATH}/{file_name}', lines=True)\n",
    "    temp_df['text_index'] = temp_df.index\n",
    "    temp_df['is_llm'] = 1\n",
    "    temp_df['dataset_name'] = Path(file_name).stem\n",
    "\n",
    "    df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "df.drop(labels=['id'], inplace=True, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'distilbert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (843 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "df['tokenized_text'] = tokenizer(list(df['text'].to_list()))['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, layers_num, device, output_size=1, dropout=0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers_num = layers_num\n",
    "        self.output_size= output_size\n",
    "        self.dropout = dropout\n",
    "        self.device = device\n",
    "\n",
    "        self.embed = nn.Embedding(self.vocab_size, self.embedding_size, device=self.device)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=self.layers_num,\n",
    "            batch_first=True,\n",
    "            dropout=self.dropout,\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(\n",
    "            self.hidden_size,\n",
    "            self.output_size\n",
    "        )\n",
    "\n",
    "    def forward(self, X, lengths):\n",
    "        embeddings = self.embed(X)\n",
    "\n",
    "        seq_output, (h_n, c_n) = self.lstm(embeddings)\n",
    "\n",
    "        out = seq_output.sum(dim=1).div(lengths.float().unsqueeze(dim=1))\n",
    "        logits = self.fc(out)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            self.X[index],\n",
    "            self.y[index]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "  # We want to sort the batch by seq length,\n",
    "  # in order to make the computation more efficient\n",
    "  batch = sorted(batch, key=lambda x: len(x[0]), reverse=True)\n",
    "\n",
    "  inputs = [torch.LongTensor(x[0]).to(device) for x in batch]\n",
    "  padded_input = nn.utils.rnn.pad_sequence(inputs, batch_first=True)\n",
    "\n",
    "  lengths = torch.LongTensor([len(x[0]) for x in batch]).to(device)\n",
    "\n",
    "  y = torch.FloatTensor(np.array([x[1] for x in batch])).reshape(-1, 1).to(device)\n",
    "\n",
    "  return padded_input, lengths, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_true, y_hat):\n",
    "    correct_pred = torch.eq(torch.sigmoid(y_hat).round(), y_true).sum().item()\n",
    "    return (correct_pred / len(y_hat)) * 100\n",
    "\n",
    "def calculate_f1(y_true, y_hat):\n",
    "    y_pred = torch.sigmoid(y_hat).round()\n",
    "    return f1_score(y_true, y_pred)\n",
    "\n",
    "def calculate_brier(y_true, y_hat):\n",
    "    y_prob = torch.sigmoid(y_hat)\n",
    "    return brier_score_loss(y_true, y_prob)\n",
    "\n",
    "def calculate_auc(y_true, y_hat):\n",
    "    y_prob = torch.sigmoid(y_hat)\n",
    "\n",
    "    false_positive_rates, true_positive_rates, _ = roc_curve(y_true, y_prob)\n",
    "    roc_auc = auc(false_positive_rates, true_positive_rates)\n",
    "\n",
    "    return roc_auc, false_positive_rates, true_positive_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model, dataloader, loss_fn, device):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    all_y_true = []\n",
    "    all_y_hat = []\n",
    "\n",
    "    test_loss = 0\n",
    "    steps = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X, lengths, y in dataloader:\n",
    "\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            y_hat = model(X, lengths)\n",
    "\n",
    "            all_y_true.extend(y)\n",
    "            all_y_hat.extend(y_hat)\n",
    "\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "        all_y_true = torch.FloatTensor(all_y_true)\n",
    "        all_y_hat = torch.FloatTensor(all_y_hat)\n",
    "\n",
    "        test_accuracy = calculate_accuracy(all_y_true, all_y_hat)\n",
    "        test_f1 = calculate_f1(all_y_true, all_y_hat)\n",
    "        test_brier = calculate_brier(all_y_true, all_y_hat)\n",
    "        test_auc_tuple = calculate_auc(all_y_true, all_y_hat)\n",
    "\n",
    "    return test_loss / steps, test_accuracy, test_f1, test_brier, test_auc_tuple\n",
    "\n",
    "def test_against_all(model, trained_llm_name, human_test_df, df, loss_fn, device):\n",
    "    all_results = []\n",
    "\n",
    "    for dataset_name in df['dataset_name'].unique():\n",
    "        if dataset_name in [trained_llm_name, Path(HUMAN_JSON_FILE_NAME).stem]:\n",
    "            continue\n",
    "\n",
    "        llm_df = df.loc[df['dataset_name'] == dataset_name]\n",
    "        llm_df_train, llm_df_test = train_test_split(llm_df, test_size=TEST_SET_FRACTION, random_state=69)\n",
    "\n",
    "        test_df_full = pd.concat([human_test_df, llm_df], ignore_index=True)\n",
    "        test_df = pd.concat([human_test_df, llm_df_test], ignore_index=True)\n",
    "\n",
    "        results_formatted = test(model, loss_fn, device, f'{dataset_name}_30_percent', test_df)\n",
    "        results_formatted_full = test(model, loss_fn, device, f'{dataset_name}_full', test_df_full)\n",
    "\n",
    "        all_results.append({\n",
    "            dataset_name: {\n",
    "                'vs_full_test_set': results_formatted_full,\n",
    "                'vs_30_percent_test_set': results_formatted\n",
    "            }\n",
    "        })\n",
    "\n",
    "    return all_results\n",
    "\n",
    "def test(model, loss_fn, device, dataset_name, test_df):\n",
    "    test_dataset_full = TextDataset(test_df['tokenized_text'], test_df['is_llm'])\n",
    "    test_dataloader_full = DataLoader(\n",
    "            test_dataset_full,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            collate_fn=collate_fn\n",
    "        )\n",
    "\n",
    "    start_time = timer()\n",
    "\n",
    "    test_loss, test_acc, test_f1, test_brier, test_auc_tuple = test_step(\n",
    "            model,\n",
    "            test_dataloader_full,\n",
    "            loss_fn,\n",
    "            device\n",
    "        )\n",
    "\n",
    "    end_time = timer()\n",
    "\n",
    "    results_formatted = {\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_acc\": test_acc,\n",
    "            \"test_f1\": test_f1,\n",
    "            \"test_brier\": test_brier,\n",
    "            \"test_auc_tuple\": test_auc_tuple\n",
    "        }\n",
    "        \n",
    "    print(\n",
    "            f\"against: {dataset_name} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f} | \"\n",
    "            f\"test_f1: {test_f1:.4f} | \"\n",
    "            f\"test_brier: {test_brier:.4f} | \"\n",
    "            f\"time: {(end_time-start_time):.4f}\"\n",
    "        )\n",
    "    \n",
    "    return results_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_df = df.loc[df['is_llm'] == 0]\n",
    "human_train_df, human_test_df = train_test_split(human_df, test_size=TEST_SET_FRACTION, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing against all LLMs for alpaca-7b...\n",
      "against: bigscience-bloomz-7b1_30_percent | test_loss: 1.2932 | test_acc: 64.2202 | test_f1: 0.4730 | test_brier: 0.3019 | time: 19.9178\n",
      "against: bigscience-bloomz-7b1_full | test_loss: 1.8277 | test_acc: 43.9887 | test_f1: 0.4367 | test_brier: 0.4611 | time: 36.0172\n",
      "against: chavinlo-alpaca-13b_30_percent | test_loss: 0.2658 | test_acc: 96.3303 | test_f1: 0.9633 | test_brier: 0.0332 | time: 20.4460\n",
      "against: chavinlo-alpaca-13b_full | test_loss: 0.2357 | test_acc: 95.1909 | test_f1: 0.9681 | test_brier: 0.0447 | time: 34.9907\n",
      "against: gemini-pro_30_percent | test_loss: 1.4381 | test_acc: 56.5749 | test_f1: 0.2792 | test_brier: 0.3498 | time: 25.8097\n",
      "against: gemini-pro_full | test_loss: 2.0200 | test_acc: 36.0679 | test_f1: 0.3014 | test_brier: 0.5272 | time: 51.6132\n",
      "against: gpt-3.5-turbo-0125_30_percent | test_loss: 0.8418 | test_acc: 68.6544 | test_f1: 0.5666 | test_brier: 0.2231 | time: 22.3669\n",
      "against: gpt-3.5-turbo-0125_full | test_loss: 1.0577 | test_acc: 55.8699 | test_f1: 0.6036 | test_brier: 0.3160 | time: 43.0259\n",
      "against: gpt-4-turbo-preview_30_percent | test_loss: 0.9915 | test_acc: 60.0917 | test_f1: 0.3741 | test_brier: 0.2750 | time: 23.8986\n",
      "against: gpt-4-turbo-preview_full | test_loss: 1.3113 | test_acc: 41.6549 | test_f1: 0.3991 | test_brier: 0.4084 | time: 51.6810\n",
      "against: meta-llama-llama-2-70b-chat-hf_30_percent | test_loss: 1.2508 | test_acc: 59.4801 | test_f1: 0.3584 | test_brier: 0.3140 | time: 24.1054\n",
      "against: meta-llama-llama-2-70b-chat-hf_full | test_loss: 1.8389 | test_acc: 37.4823 | test_f1: 0.3272 | test_brier: 0.4954 | time: 49.3973\n",
      "against: meta-llama-llama-2-7b-chat-hf_30_percent | test_loss: 1.3376 | test_acc: 58.7156 | test_f1: 0.3382 | test_brier: 0.3320 | time: 23.5635\n",
      "against: meta-llama-llama-2-7b-chat-hf_full | test_loss: 1.8839 | test_acc: 37.3409 | test_f1: 0.3247 | test_brier: 0.5022 | time: 47.0396\n",
      "against: mistralai-mistral-7b-instruct-v0.2_30_percent | test_loss: 1.2855 | test_acc: 58.5627 | test_f1: 0.3342 | test_brier: 0.3283 | time: 25.7954\n",
      "against: mistralai-mistral-7b-instruct-v0.2_full | test_loss: 1.8612 | test_acc: 36.1386 | test_f1: 0.3027 | test_brier: 0.5088 | time: 55.6884\n",
      "against: mistralai-mixtral-8x7b-instruct-v0.1_30_percent | test_loss: 1.1630 | test_acc: 59.3272 | test_f1: 0.3544 | test_brier: 0.3027 | time: 25.7459\n",
      "against: mistralai-mixtral-8x7b-instruct-v0.1_full | test_loss: 1.6351 | test_acc: 38.3310 | test_f1: 0.3424 | test_brier: 0.4674 | time: 57.9112\n",
      "against: qwen-qwen1.5-72b-chat-8bit_30_percent | test_loss: 1.5285 | test_acc: 51.6820 | test_f1: 0.1271 | test_brier: 0.3859 | time: 25.8922\n",
      "against: qwen-qwen1.5-72b-chat-8bit_full | test_loss: 2.2510 | test_acc: 28.4300 | test_f1: 0.1467 | test_brier: 0.5921 | time: 48.9953\n",
      "against: text-bison-002_30_percent | test_loss: 1.0590 | test_acc: 62.2324 | test_f1: 0.4269 | test_brier: 0.2750 | time: 33.0889\n",
      "against: text-bison-002_full | test_loss: 1.4049 | test_acc: 45.6860 | test_f1: 0.4629 | test_brier: 0.4047 | time: 68.7048\n",
      "against: vicgalle-gpt2-open-instruct-v1_30_percent | test_loss: 0.9657 | test_acc: 71.4067 | test_f1: 0.6191 | test_brier: 0.2282 | time: 25.7756\n",
      "against: vicgalle-gpt2-open-instruct-v1_full | test_loss: 1.3369 | test_acc: 55.0212 | test_f1: 0.5928 | test_brier: 0.3570 | time: 49.6004\n",
      "Finished testing against all LLms for alpaca-7b\n",
      "Testing against all LLMs for bigscience-bloomz-7b1...\n",
      "against: alpaca-7b_30_percent | test_loss: 0.8794 | test_acc: 75.8410 | test_f1: 0.6962 | test_brier: 0.1867 | time: 24.5013\n",
      "against: alpaca-7b_full | test_loss: 1.1087 | test_acc: 64.0736 | test_f1: 0.6994 | test_brier: 0.2827 | time: 42.0607\n",
      "against: chavinlo-alpaca-13b_30_percent | test_loss: 0.8658 | test_acc: 79.5107 | test_f1: 0.7537 | test_brier: 0.1683 | time: 27.1392\n",
      "against: chavinlo-alpaca-13b_full | test_loss: 1.2560 | test_acc: 63.0835 | test_f1: 0.6885 | test_brier: 0.2925 | time: 47.1424\n",
      "against: gemini-pro_30_percent | test_loss: 2.1146 | test_acc: 52.9052 | test_f1: 0.1676 | test_brier: 0.4258 | time: 31.1973\n",
      "against: gemini-pro_full | test_loss: 2.9351 | test_acc: 28.8543 | test_f1: 0.1560 | test_brier: 0.6377 | time: 64.6794\n",
      "against: gpt-3.5-turbo-0125_30_percent | test_loss: 1.8225 | test_acc: 52.1407 | test_f1: 0.1425 | test_brier: 0.4057 | time: 28.5353\n",
      "against: gpt-3.5-turbo-0125_full | test_loss: 2.4962 | test_acc: 29.3494 | test_f1: 0.1668 | test_brier: 0.6012 | time: 56.0931\n",
      "against: gpt-4-turbo-preview_30_percent | test_loss: 2.2286 | test_acc: 49.2355 | test_f1: 0.0405 | test_brier: 0.4605 | time: 31.4655\n",
      "against: gpt-4-turbo-preview_full | test_loss: 3.1039 | test_acc: 24.3281 | test_f1: 0.0514 | test_brier: 0.6893 | time: 66.6688\n",
      "against: meta-llama-llama-2-70b-chat-hf_30_percent | test_loss: 1.8617 | test_acc: 54.2813 | test_f1: 0.2111 | test_brier: 0.3945 | time: 34.2415\n",
      "against: meta-llama-llama-2-70b-chat-hf_full | test_loss: 2.6680 | test_acc: 30.9052 | test_f1: 0.1998 | test_brier: 0.6029 | time: 65.3749\n",
      "against: meta-llama-llama-2-7b-chat-hf_30_percent | test_loss: 2.0720 | test_acc: 52.7523 | test_f1: 0.1626 | test_brier: 0.4189 | time: 30.8402\n",
      "against: meta-llama-llama-2-7b-chat-hf_full | test_loss: 2.9287 | test_acc: 29.2079 | test_f1: 0.1637 | test_brier: 0.6319 | time: 61.0213\n",
      "against: mistralai-mistral-7b-instruct-v0.2_30_percent | test_loss: 2.2084 | test_acc: 51.8349 | test_f1: 0.1322 | test_brier: 0.4360 | time: 33.2004\n",
      "against: mistralai-mistral-7b-instruct-v0.2_full | test_loss: 3.1828 | test_acc: 26.3791 | test_f1: 0.1003 | test_brier: 0.6684 | time: 70.4755\n",
      "against: mistralai-mixtral-8x7b-instruct-v0.1_30_percent | test_loss: 1.9969 | test_acc: 51.5291 | test_f1: 0.1219 | test_brier: 0.4207 | time: 32.4762\n",
      "against: mistralai-mixtral-8x7b-instruct-v0.1_full | test_loss: 2.8900 | test_acc: 26.5205 | test_f1: 0.1035 | test_brier: 0.6515 | time: 72.0214\n",
      "against: qwen-qwen1.5-72b-chat-8bit_30_percent | test_loss: 2.5339 | test_acc: 48.6239 | test_f1: 0.0175 | test_brier: 0.4771 | time: 28.7219\n",
      "against: qwen-qwen1.5-72b-chat-8bit_full | test_loss: 3.6795 | test_acc: 23.0552 | test_f1: 0.0198 | test_brier: 0.7214 | time: 50.5839\n",
      "against: text-bison-002_30_percent | test_loss: 2.0861 | test_acc: 51.2232 | test_f1: 0.1114 | test_brier: 0.4303 | time: 31.2881\n",
      "against: text-bison-002_full | test_loss: 2.8555 | test_acc: 27.0863 | test_f1: 0.1165 | test_brier: 0.6455 | time: 65.8146\n",
      "against: vicgalle-gpt2-open-instruct-v1_30_percent | test_loss: 1.3192 | test_acc: 65.7492 | test_f1: 0.5066 | test_brier: 0.2832 | time: 25.4770\n",
      "against: vicgalle-gpt2-open-instruct-v1_full | test_loss: 1.7732 | test_acc: 46.1810 | test_f1: 0.4704 | test_brier: 0.4292 | time: 47.0815\n",
      "Finished testing against all LLms for bigscience-bloomz-7b1\n",
      "Testing against all LLMs for chavinlo-alpaca-13b...\n",
      "against: alpaca-7b_30_percent | test_loss: 0.3418 | test_acc: 93.5780 | test_f1: 0.9327 | test_brier: 0.0533 | time: 26.0200\n",
      "against: alpaca-7b_full | test_loss: 0.3404 | test_acc: 90.4526 | test_f1: 0.9342 | test_brier: 0.0754 | time: 43.8696\n",
      "against: bigscience-bloomz-7b1_30_percent | test_loss: 1.4752 | test_acc: 62.3853 | test_f1: 0.4143 | test_brier: 0.3170 | time: 27.8949\n",
      "against: bigscience-bloomz-7b1_full | test_loss: 2.1762 | test_acc: 41.5134 | test_f1: 0.3915 | test_brier: 0.4988 | time: 47.8908\n",
      "against: gemini-pro_30_percent | test_loss: 1.7471 | test_acc: 56.4220 | test_f1: 0.2520 | test_brier: 0.3854 | time: 32.9490\n",
      "against: gemini-pro_full | test_loss: 2.4626 | test_acc: 34.7949 | test_f1: 0.2706 | test_brier: 0.5722 | time: 66.6120\n",
      "against: gpt-3.5-turbo-0125_30_percent | test_loss: 0.9683 | test_acc: 64.8318 | test_f1: 0.4725 | test_brier: 0.2539 | time: 32.5057\n",
      "against: gpt-3.5-turbo-0125_full | test_loss: 1.2368 | test_acc: 50.0707 | test_f1: 0.5230 | test_brier: 0.3628 | time: 67.3095\n",
      "against: gpt-4-turbo-preview_30_percent | test_loss: 1.1998 | test_acc: 58.4098 | test_f1: 0.3096 | test_brier: 0.3221 | time: 38.3435\n",
      "against: gpt-4-turbo-preview_full | test_loss: 1.6581 | test_acc: 36.9873 | test_f1: 0.3120 | test_brier: 0.4808 | time: 71.3976\n",
      "against: meta-llama-llama-2-70b-chat-hf_30_percent | test_loss: 1.4529 | test_acc: 58.8685 | test_f1: 0.3224 | test_brier: 0.3374 | time: 31.7626\n",
      "against: meta-llama-llama-2-70b-chat-hf_full | test_loss: 2.1404 | test_acc: 36.8458 | test_f1: 0.3094 | test_brier: 0.5294 | time: 64.4577\n",
      "against: meta-llama-llama-2-7b-chat-hf_30_percent | test_loss: 1.5564 | test_acc: 57.9511 | test_f1: 0.2967 | test_brier: 0.3557 | time: 31.4577\n",
      "against: meta-llama-llama-2-7b-chat-hf_full | test_loss: 2.2406 | test_acc: 35.9972 | test_f1: 0.2935 | test_brier: 0.5409 | time: 64.4961\n",
      "against: mistralai-mistral-7b-instruct-v0.2_30_percent | test_loss: 1.5741 | test_acc: 57.6453 | test_f1: 0.2879 | test_brier: 0.3615 | time: 34.4029\n",
      "against: mistralai-mistral-7b-instruct-v0.2_full | test_loss: 2.3233 | test_acc: 34.2291 | test_f1: 0.2596 | test_brier: 0.5652 | time: 75.8285\n",
      "against: mistralai-mixtral-8x7b-instruct-v0.1_30_percent | test_loss: 1.3411 | test_acc: 59.3272 | test_f1: 0.3350 | test_brier: 0.3273 | time: 32.8580\n",
      "against: mistralai-mixtral-8x7b-instruct-v0.1_full | test_loss: 1.9663 | test_acc: 36.7044 | test_f1: 0.3067 | test_brier: 0.5145 | time: 66.8435\n",
      "against: qwen-qwen1.5-72b-chat-8bit_30_percent | test_loss: 1.7712 | test_acc: 52.4465 | test_f1: 0.1239 | test_brier: 0.4092 | time: 26.8768\n",
      "against: qwen-qwen1.5-72b-chat-8bit_full | test_loss: 2.7015 | test_acc: 26.8034 | test_f1: 0.1008 | test_brier: 0.6356 | time: 48.5584\n",
      "against: text-bison-002_30_percent | test_loss: 1.3055 | test_acc: 59.1743 | test_f1: 0.3308 | test_brier: 0.3188 | time: 31.2543\n",
      "against: text-bison-002_full | test_loss: 1.7667 | test_acc: 40.0283 | test_f1: 0.3662 | test_brier: 0.4705 | time: 66.1126\n",
      "against: vicgalle-gpt2-open-instruct-v1_30_percent | test_loss: 1.0011 | test_acc: 72.1713 | test_f1: 0.6240 | test_brier: 0.2271 | time: 26.6059\n",
      "against: vicgalle-gpt2-open-instruct-v1_full | test_loss: 1.4847 | test_acc: 54.3847 | test_f1: 0.5814 | test_brier: 0.3703 | time: 47.8798\n",
      "Finished testing against all LLms for chavinlo-alpaca-13b\n",
      "Testing against all LLMs for gemini-pro...\n",
      "against: alpaca-7b_30_percent | test_loss: 3.8764 | test_acc: 62.5382 | test_f1: 0.4342 | test_brier: 0.3468 | time: 24.6105\n",
      "against: alpaca-7b_full | test_loss: 6.3260 | test_acc: 44.2716 | test_f1: 0.4411 | test_brier: 0.5097 | time: 42.7850\n",
      "against: bigscience-bloomz-7b1_30_percent | test_loss: 1.4984 | test_acc: 59.3272 | test_f1: 0.3544 | test_brier: 0.3554 | time: 25.4729\n",
      "against: bigscience-bloomz-7b1_full | test_loss: 2.2223 | test_acc: 38.5431 | test_f1: 0.3461 | test_brier: 0.5345 | time: 46.5662\n",
      "against: chavinlo-alpaca-13b_30_percent | test_loss: 3.9798 | test_acc: 57.6453 | test_f1: 0.3092 | test_brier: 0.4002 | time: 26.7331\n",
      "against: chavinlo-alpaca-13b_full | test_loss: 5.7182 | test_acc: 40.0990 | test_f1: 0.3731 | test_brier: 0.5613 | time: 47.0482\n",
      "against: gpt-3.5-turbo-0125_30_percent | test_loss: 0.4763 | test_acc: 84.4037 | test_f1: 0.8223 | test_brier: 0.1223 | time: 26.9815\n",
      "against: gpt-3.5-turbo-0125_full | test_loss: 0.5813 | test_acc: 78.0764 | test_f1: 0.8358 | test_brier: 0.1626 | time: 54.6803\n",
      "against: gpt-4-turbo-preview_30_percent | test_loss: 0.3265 | test_acc: 87.6147 | test_f1: 0.8639 | test_brier: 0.0982 | time: 31.2523\n",
      "against: gpt-4-turbo-preview_full | test_loss: 0.3837 | test_acc: 84.9364 | test_f1: 0.8927 | test_brier: 0.1143 | time: 64.9463\n",
      "against: meta-llama-llama-2-70b-chat-hf_30_percent | test_loss: 0.1716 | test_acc: 93.5780 | test_f1: 0.9340 | test_brier: 0.0503 | time: 33.1134\n",
      "against: meta-llama-llama-2-70b-chat-hf_full | test_loss: 0.1760 | test_acc: 93.7765 | test_f1: 0.9583 | test_brier: 0.0487 | time: 69.3019\n",
      "against: meta-llama-llama-2-7b-chat-hf_30_percent | test_loss: 0.3013 | test_acc: 89.4495 | test_f1: 0.8863 | test_brier: 0.0844 | time: 32.3534\n",
      "against: meta-llama-llama-2-7b-chat-hf_full | test_loss: 0.3109 | test_acc: 88.3310 | test_f1: 0.9188 | test_brier: 0.0867 | time: 64.5153\n",
      "against: mistralai-mistral-7b-instruct-v0.2_30_percent | test_loss: 0.3057 | test_acc: 88.6850 | test_f1: 0.8771 | test_brier: 0.0882 | time: 32.4409\n",
      "against: mistralai-mistral-7b-instruct-v0.2_full | test_loss: 0.3586 | test_acc: 86.7751 | test_f1: 0.9069 | test_brier: 0.1026 | time: 70.3644\n",
      "against: mistralai-mixtral-8x7b-instruct-v0.1_30_percent | test_loss: 0.4098 | test_acc: 84.8624 | test_f1: 0.8284 | test_brier: 0.1185 | time: 31.9594\n",
      "against: mistralai-mixtral-8x7b-instruct-v0.1_full | test_loss: 0.4752 | test_acc: 81.3296 | test_f1: 0.8634 | test_brier: 0.1410 | time: 67.8079\n",
      "against: qwen-qwen1.5-72b-chat-8bit_30_percent | test_loss: 0.2733 | test_acc: 88.8379 | test_f1: 0.8793 | test_brier: 0.0828 | time: 26.0850\n",
      "against: qwen-qwen1.5-72b-chat-8bit_full | test_loss: 0.2856 | test_acc: 87.6945 | test_f1: 0.9140 | test_brier: 0.0854 | time: 47.5036\n",
      "against: text-bison-002_30_percent | test_loss: 1.9292 | test_acc: 91.7431 | test_f1: 0.9132 | test_brier: 0.0675 | time: 31.4072\n",
      "against: text-bison-002_full | test_loss: 1.0199 | test_acc: 92.5743 | test_f1: 0.9498 | test_brier: 0.0594 | time: 64.3116\n",
      "against: vicgalle-gpt2-open-instruct-v1_30_percent | test_loss: 0.9158 | test_acc: 74.6177 | test_f1: 0.6758 | test_brier: 0.2083 | time: 25.4505\n",
      "against: vicgalle-gpt2-open-instruct-v1_full | test_loss: 1.1183 | test_acc: 64.4272 | test_f1: 0.7032 | test_brier: 0.2844 | time: 47.6727\n",
      "Finished testing against all LLms for gemini-pro\n",
      "Testing against all LLMs for gpt-3.5-turbo-0125...\n",
      "against: alpaca-7b_30_percent | test_loss: 0.6328 | test_acc: 86.6972 | test_f1: 0.8595 | test_brier: 0.1048 | time: 24.9111\n",
      "against: alpaca-7b_full | test_loss: 0.6541 | test_acc: 83.2390 | test_f1: 0.8808 | test_brier: 0.1372 | time: 45.2367\n",
      "against: bigscience-bloomz-7b1_30_percent | test_loss: 1.8245 | test_acc: 60.8563 | test_f1: 0.4311 | test_brier: 0.3419 | time: 26.0416\n",
      "against: bigscience-bloomz-7b1_full | test_loss: 2.7093 | test_acc: 40.5941 | test_f1: 0.3939 | test_brier: 0.5297 | time: 47.6639\n",
      "against: chavinlo-alpaca-13b_30_percent | test_loss: 0.5140 | test_acc: 88.0734 | test_f1: 0.8758 | test_brier: 0.0938 | time: 28.0753\n",
      "against: chavinlo-alpaca-13b_full | test_loss: 0.5747 | test_acc: 84.2291 | test_f1: 0.8887 | test_brier: 0.1259 | time: 47.6357\n",
      "against: gemini-pro_30_percent | test_loss: 1.3228 | test_acc: 62.9969 | test_f1: 0.4784 | test_brier: 0.3060 | time: 31.6459\n",
      "against: gemini-pro_full | test_loss: 1.8211 | test_acc: 46.8883 | test_f1: 0.4908 | test_brier: 0.4439 | time: 67.3495\n",
      "against: gpt-4-turbo-preview_30_percent | test_loss: 0.3839 | test_acc: 92.3547 | test_f1: 0.9238 | test_brier: 0.0626 | time: 34.2164\n",
      "against: gpt-4-turbo-preview_full | test_loss: 0.3222 | test_acc: 92.5743 | test_f1: 0.9505 | test_brier: 0.0668 | time: 68.6806\n",
      "against: meta-llama-llama-2-70b-chat-hf_30_percent | test_loss: 0.8000 | test_acc: 74.3119 | test_f1: 0.6877 | test_brier: 0.1851 | time: 34.4725\n",
      "against: meta-llama-llama-2-70b-chat-hf_full | test_loss: 1.0853 | test_acc: 62.4470 | test_f1: 0.6867 | test_brier: 0.2867 | time: 63.6328\n",
      "against: meta-llama-llama-2-7b-chat-hf_30_percent | test_loss: 0.9012 | test_acc: 71.8654 | test_f1: 0.6475 | test_brier: 0.2131 | time: 31.3496\n",
      "against: meta-llama-llama-2-7b-chat-hf_full | test_loss: 1.1547 | test_acc: 60.7496 | test_f1: 0.6679 | test_brier: 0.3006 | time: 61.9616\n",
      "against: mistralai-mistral-7b-instruct-v0.2_30_percent | test_loss: 0.8378 | test_acc: 74.1590 | test_f1: 0.6853 | test_brier: 0.1953 | time: 33.3507\n",
      "against: mistralai-mistral-7b-instruct-v0.2_full | test_loss: 1.0282 | test_acc: 65.7001 | test_f1: 0.7214 | test_brier: 0.2682 | time: 71.3794\n",
      "against: mistralai-mixtral-8x7b-instruct-v0.1_30_percent | test_loss: 0.6610 | test_acc: 79.2049 | test_f1: 0.7614 | test_brier: 0.1518 | time: 32.6065\n",
      "against: mistralai-mixtral-8x7b-instruct-v0.1_full | test_loss: 0.7845 | test_acc: 72.3479 | test_f1: 0.7869 | test_brier: 0.2080 | time: 68.3542\n",
      "against: qwen-qwen1.5-72b-chat-8bit_30_percent | test_loss: 0.6205 | test_acc: 79.3578 | test_f1: 0.7636 | test_brier: 0.1464 | time: 26.1675\n",
      "against: qwen-qwen1.5-72b-chat-8bit_full | test_loss: 0.7283 | test_acc: 71.5700 | test_f1: 0.7796 | test_brier: 0.2041 | time: 48.1802\n",
      "against: text-bison-002_30_percent | test_loss: 0.6732 | test_acc: 80.1223 | test_f1: 0.7743 | test_brier: 0.1494 | time: 31.0964\n",
      "against: text-bison-002_full | test_loss: 0.7398 | test_acc: 74.3281 | test_f1: 0.8052 | test_brier: 0.1926 | time: 63.8565\n",
      "against: vicgalle-gpt2-open-instruct-v1_30_percent | test_loss: 1.2614 | test_acc: 68.1957 | test_f1: 0.5823 | test_brier: 0.2553 | time: 25.7367\n",
      "against: vicgalle-gpt2-open-instruct-v1_full | test_loss: 1.8298 | test_acc: 53.7482 | test_f1: 0.5840 | test_brier: 0.3868 | time: 49.0551\n",
      "Finished testing against all LLms for gpt-3.5-turbo-0125\n",
      "Testing against all LLMs for gpt-4-turbo-preview...\n",
      "against: alpaca-7b_30_percent | test_loss: 8.6984 | test_acc: 55.5046 | test_f1: 0.2322 | test_brier: 0.4155 | time: 24.8938\n",
      "against: alpaca-7b_full | test_loss: 14.6061 | test_acc: 32.7440 | test_f1: 0.2324 | test_brier: 0.6292 | time: 43.0378\n",
      "against: bigscience-bloomz-7b1_30_percent | test_loss: 2.3117 | test_acc: 53.2110 | test_f1: 0.1593 | test_brier: 0.4173 | time: 25.6025\n",
      "against: bigscience-bloomz-7b1_full | test_loss: 3.3747 | test_acc: 28.7129 | test_f1: 0.1472 | test_brier: 0.6448 | time: 47.9574\n",
      "against: chavinlo-alpaca-13b_30_percent | test_loss: 8.1988 | test_acc: 54.4343 | test_f1: 0.1989 | test_brier: 0.4315 | time: 28.0823\n",
      "against: chavinlo-alpaca-13b_full | test_loss: 11.9995 | test_acc: 32.8854 | test_f1: 0.2353 | test_brier: 0.6267 | time: 46.8072\n",
      "against: gemini-pro_30_percent | test_loss: 1.2258 | test_acc: 64.3731 | test_f1: 0.4668 | test_brier: 0.2972 | time: 31.0391\n",
      "against: gemini-pro_full | test_loss: 1.7594 | test_acc: 47.1004 | test_f1: 0.4813 | test_brier: 0.4349 | time: 66.3587\n",
      "against: gpt-3.5-turbo-0125_30_percent | test_loss: 0.3384 | test_acc: 94.1896 | test_f1: 0.9399 | test_brier: 0.0458 | time: 27.2583\n",
      "against: gpt-3.5-turbo-0125_full | test_loss: 0.2976 | test_acc: 92.0085 | test_f1: 0.9456 | test_brier: 0.0590 | time: 54.5671\n",
      "against: meta-llama-llama-2-70b-chat-hf_30_percent | test_loss: 0.6758 | test_acc: 73.8532 | test_f1: 0.6573 | test_brier: 0.1967 | time: 30.8522\n",
      "against: meta-llama-llama-2-70b-chat-hf_full | test_loss: 0.8177 | test_acc: 66.4781 | test_f1: 0.7238 | test_brier: 0.2500 | time: 62.4019\n",
      "against: meta-llama-llama-2-7b-chat-hf_30_percent | test_loss: 0.8147 | test_acc: 72.9358 | test_f1: 0.6410 | test_brier: 0.2153 | time: 30.4045\n",
      "against: meta-llama-llama-2-7b-chat-hf_full | test_loss: 1.0684 | test_acc: 61.7397 | test_f1: 0.6719 | test_brier: 0.2972 | time: 59.1767\n",
      "against: mistralai-mistral-7b-instruct-v0.2_30_percent | test_loss: 0.6226 | test_acc: 77.3700 | test_f1: 0.7165 | test_brier: 0.1717 | time: 33.1081\n",
      "against: mistralai-mistral-7b-instruct-v0.2_full | test_loss: 0.8616 | test_acc: 66.2659 | test_f1: 0.7215 | test_brier: 0.2525 | time: 68.5042\n",
      "against: mistralai-mixtral-8x7b-instruct-v0.1_30_percent | test_loss: 0.6060 | test_acc: 77.5229 | test_f1: 0.7189 | test_brier: 0.1655 | time: 32.7200\n",
      "against: mistralai-mixtral-8x7b-instruct-v0.1_full | test_loss: 0.7247 | test_acc: 72.6308 | test_f1: 0.7854 | test_brier: 0.2074 | time: 67.3558\n",
      "against: qwen-qwen1.5-72b-chat-8bit_30_percent | test_loss: 0.0949 | test_acc: 97.4006 | test_f1: 0.9740 | test_brier: 0.0234 | time: 25.1482\n",
      "against: qwen-qwen1.5-72b-chat-8bit_full | test_loss: 0.1113 | test_acc: 95.5446 | test_f1: 0.9704 | test_brier: 0.0311 | time: 48.4097\n",
      "against: text-bison-002_30_percent | test_loss: 5.0041 | test_acc: 86.8502 | test_f1: 0.8527 | test_brier: 0.1022 | time: 30.5727\n",
      "against: text-bison-002_full | test_loss: 2.7078 | test_acc: 82.3197 | test_f1: 0.8711 | test_brier: 0.1380 | time: 64.5271\n",
      "against: vicgalle-gpt2-open-instruct-v1_30_percent | test_loss: 1.3421 | test_acc: 69.2661 | test_f1: 0.5714 | test_brier: 0.2483 | time: 27.1378\n",
      "against: vicgalle-gpt2-open-instruct-v1_full | test_loss: 1.5947 | test_acc: 52.1216 | test_f1: 0.5525 | test_brier: 0.3825 | time: 47.0353\n",
      "Finished testing against all LLms for gpt-4-turbo-preview\n",
      "Testing against all LLMs for meta-llama-llama-2-70b-chat-hf...\n",
      "against: alpaca-7b_30_percent | test_loss: 8.2591 | test_acc: 55.8104 | test_f1: 0.2454 | test_brier: 0.4091 | time: 28.0174\n",
      "against: alpaca-7b_full | test_loss: 13.7319 | test_acc: 35.8557 | test_f1: 0.2942 | test_brier: 0.6061 | time: 44.7399\n",
      "against: bigscience-bloomz-7b1_30_percent | test_loss: 2.0415 | test_acc: 56.2691 | test_f1: 0.2591 | test_brier: 0.3891 | time: 25.8465\n",
      "against: bigscience-bloomz-7b1_full | test_loss: 2.8921 | test_acc: 34.7242 | test_f1: 0.2727 | test_brier: 0.5840 | time: 47.1762\n",
      "against: chavinlo-alpaca-13b_30_percent | test_loss: 7.9603 | test_acc: 55.1988 | test_f1: 0.2269 | test_brier: 0.4347 | time: 25.7456\n",
      "against: chavinlo-alpaca-13b_full | test_loss: 11.5358 | test_acc: 35.0071 | test_f1: 0.2781 | test_brier: 0.6144 | time: 46.5640\n",
      "against: gemini-pro_30_percent | test_loss: 0.4401 | test_acc: 85.1682 | test_f1: 0.8307 | test_brier: 0.1175 | time: 30.7953\n",
      "against: gemini-pro_full | test_loss: 0.5161 | test_acc: 82.3197 | test_f1: 0.8711 | test_brier: 0.1357 | time: 67.6437\n",
      "against: gpt-3.5-turbo-0125_30_percent | test_loss: 0.4597 | test_acc: 90.2141 | test_f1: 0.8944 | test_brier: 0.0797 | time: 29.8243\n",
      "against: gpt-3.5-turbo-0125_full | test_loss: 0.4517 | test_acc: 87.5530 | test_f1: 0.9127 | test_brier: 0.0988 | time: 56.7018\n",
      "against: gpt-4-turbo-preview_30_percent | test_loss: 0.1974 | test_acc: 92.9664 | test_f1: 0.9263 | test_brier: 0.0562 | time: 32.4315\n",
      "against: gpt-4-turbo-preview_full | test_loss: 0.2013 | test_acc: 92.2914 | test_f1: 0.9476 | test_brier: 0.0584 | time: 72.5012\n",
      "against: meta-llama-llama-2-7b-chat-hf_30_percent | test_loss: 0.2224 | test_acc: 93.4251 | test_f1: 0.9314 | test_brier: 0.0519 | time: 30.1684\n",
      "against: meta-llama-llama-2-7b-chat-hf_full | test_loss: 0.2281 | test_acc: 93.2107 | test_f1: 0.9542 | test_brier: 0.0519 | time: 61.5431\n",
      "against: mistralai-mistral-7b-instruct-v0.2_30_percent | test_loss: 0.2877 | test_acc: 89.9083 | test_f1: 0.8907 | test_brier: 0.0804 | time: 33.6620\n",
      "against: mistralai-mistral-7b-instruct-v0.2_full | test_loss: 0.3227 | test_acc: 87.9066 | test_f1: 0.9153 | test_brier: 0.0917 | time: 72.7459\n",
      "against: mistralai-mixtral-8x7b-instruct-v0.1_30_percent | test_loss: 0.3553 | test_acc: 88.0734 | test_f1: 0.8682 | test_brier: 0.0937 | time: 35.0243\n",
      "against: mistralai-mixtral-8x7b-instruct-v0.1_full | test_loss: 0.3652 | test_acc: 87.1287 | test_f1: 0.9094 | test_brier: 0.0994 | time: 73.9569\n",
      "against: qwen-qwen1.5-72b-chat-8bit_30_percent | test_loss: 0.1164 | test_acc: 95.5657 | test_f1: 0.9549 | test_brier: 0.0323 | time: 26.2538\n",
      "against: qwen-qwen1.5-72b-chat-8bit_full | test_loss: 0.1033 | test_acc: 95.6860 | test_f1: 0.9714 | test_brier: 0.0301 | time: 49.4062\n",
      "against: text-bison-002_30_percent | test_loss: 4.5057 | test_acc: 91.4373 | test_f1: 0.9088 | test_brier: 0.0671 | time: 32.8605\n",
      "against: text-bison-002_full | test_loss: 2.2750 | test_acc: 90.8062 | test_f1: 0.9369 | test_brier: 0.0687 | time: 69.1476\n",
      "against: vicgalle-gpt2-open-instruct-v1_30_percent | test_loss: 0.9976 | test_acc: 79.9694 | test_f1: 0.7579 | test_brier: 0.1636 | time: 25.4455\n",
      "against: vicgalle-gpt2-open-instruct-v1_full | test_loss: 1.0626 | test_acc: 71.9236 | test_f1: 0.7788 | test_brier: 0.2301 | time: 49.2815\n",
      "Finished testing against all LLms for meta-llama-llama-2-70b-chat-hf\n",
      "Testing against all LLMs for meta-llama-llama-2-7b-chat-hf...\n",
      "against: alpaca-7b_30_percent | test_loss: 0.6051 | test_acc: 87.0031 | test_f1: 0.8666 | test_brier: 0.1007 | time: 24.3885\n",
      "against: alpaca-7b_full | test_loss: 0.5737 | test_acc: 85.0778 | test_f1: 0.8961 | test_brier: 0.1194 | time: 42.5378\n",
      "against: bigscience-bloomz-7b1_30_percent | test_loss: 1.7916 | test_acc: 60.8563 | test_f1: 0.4506 | test_brier: 0.3376 | time: 25.1039\n",
      "against: bigscience-bloomz-7b1_full | test_loss: 2.4038 | test_acc: 44.0594 | test_f1: 0.4549 | test_brier: 0.4888 | time: 46.9538\n",
      "against: chavinlo-alpaca-13b_30_percent | test_loss: 0.5438 | test_acc: 87.7676 | test_f1: 0.8754 | test_brier: 0.0966 | time: 26.3312\n",
      "against: chavinlo-alpaca-13b_full | test_loss: 0.5260 | test_acc: 85.7850 | test_f1: 0.9015 | test_brier: 0.1108 | time: 47.4945\n",
      "against: gemini-pro_30_percent | test_loss: 0.5083 | test_acc: 86.8502 | test_f1: 0.8652 | test_brier: 0.0949 | time: 33.0675\n",
      "against: gemini-pro_full | test_loss: 0.4177 | test_acc: 87.1287 | test_f1: 0.9117 | test_brier: 0.0939 | time: 71.0903\n",
      "against: gpt-3.5-turbo-0125_30_percent | test_loss: 0.5575 | test_acc: 85.9327 | test_f1: 0.8544 | test_brier: 0.1081 | time: 28.5539\n",
      "against: gpt-3.5-turbo-0125_full | test_loss: 0.4455 | test_acc: 85.5728 | test_f1: 0.9000 | test_brier: 0.1067 | time: 56.3338\n",
      "against: gpt-4-turbo-preview_30_percent | test_loss: 0.5129 | test_acc: 87.4618 | test_f1: 0.8723 | test_brier: 0.0987 | time: 32.1562\n",
      "against: gpt-4-turbo-preview_full | test_loss: 0.4217 | test_acc: 86.9165 | test_f1: 0.9102 | test_brier: 0.0989 | time: 69.0836\n",
      "against: meta-llama-llama-2-70b-chat-hf_30_percent | test_loss: 0.4167 | test_acc: 91.5902 | test_f1: 0.9178 | test_brier: 0.0646 | time: 32.5884\n",
      "against: meta-llama-llama-2-70b-chat-hf_full | test_loss: 0.3116 | test_acc: 93.4229 | test_f1: 0.9568 | test_brier: 0.0567 | time: 71.2600\n",
      "against: mistralai-mistral-7b-instruct-v0.2_30_percent | test_loss: 0.4971 | test_acc: 88.0734 | test_f1: 0.8793 | test_brier: 0.0904 | time: 34.0828\n",
      "against: mistralai-mistral-7b-instruct-v0.2_full | test_loss: 0.3873 | test_acc: 89.5332 | test_f1: 0.9294 | test_brier: 0.0845 | time: 73.9224\n",
      "against: mistralai-mixtral-8x7b-instruct-v0.1_30_percent | test_loss: 0.5110 | test_acc: 87.7676 | test_f1: 0.8758 | test_brier: 0.0948 | time: 33.8777\n",
      "against: mistralai-mixtral-8x7b-instruct-v0.1_full | test_loss: 0.4420 | test_acc: 86.9873 | test_f1: 0.9107 | test_brier: 0.1012 | time: 68.1729\n",
      "against: qwen-qwen1.5-72b-chat-8bit_30_percent | test_loss: 0.5312 | test_acc: 87.4618 | test_f1: 0.8719 | test_brier: 0.1017 | time: 27.6096\n",
      "against: qwen-qwen1.5-72b-chat-8bit_full | test_loss: 0.4772 | test_acc: 85.0778 | test_f1: 0.8961 | test_brier: 0.1164 | time: 49.6276\n",
      "against: text-bison-002_30_percent | test_loss: 0.5030 | test_acc: 87.4618 | test_f1: 0.8723 | test_brier: 0.0938 | time: 31.0887\n",
      "against: text-bison-002_full | test_loss: 0.3812 | test_acc: 89.8868 | test_f1: 0.9319 | test_brier: 0.0836 | time: 66.3325\n",
      "against: vicgalle-gpt2-open-instruct-v1_30_percent | test_loss: 1.0571 | test_acc: 72.0183 | test_f1: 0.6605 | test_brier: 0.2201 | time: 27.0840\n",
      "against: vicgalle-gpt2-open-instruct-v1_full | test_loss: 1.3829 | test_acc: 62.5884 | test_f1: 0.6912 | test_brier: 0.3075 | time: 50.7353\n",
      "Finished testing against all LLms for meta-llama-llama-2-7b-chat-hf\n",
      "Testing against all LLMs for mistralai-mistral-7b-instruct-v0.2...\n",
      "against: alpaca-7b_30_percent | test_loss: 7.8614 | test_acc: 57.0336 | test_f1: 0.4277 | test_brier: 0.3680 | time: 25.3403\n",
      "against: alpaca-7b_full | test_loss: 13.4011 | test_acc: 47.1004 | test_f1: 0.5155 | test_brier: 0.4658 | time: 45.4040\n",
      "against: bigscience-bloomz-7b1_30_percent | test_loss: 1.6644 | test_acc: 62.9969 | test_f1: 0.5434 | test_brier: 0.3140 | time: 25.3784\n",
      "against: bigscience-bloomz-7b1_full | test_loss: 2.1525 | test_acc: 50.7072 | test_f1: 0.5630 | test_brier: 0.4238 | time: 46.5352\n",
      "against: chavinlo-alpaca-13b_30_percent | test_loss: 7.3881 | test_acc: 57.4924 | test_f1: 0.4372 | test_brier: 0.3803 | time: 27.1334\n",
      "against: chavinlo-alpaca-13b_full | test_loss: 10.7134 | test_acc: 46.1103 | test_f1: 0.5020 | test_brier: 0.4841 | time: 46.1301\n",
      "against: gemini-pro_30_percent | test_loss: 0.3674 | test_acc: 87.3089 | test_f1: 0.8795 | test_brier: 0.0985 | time: 31.7176\n",
      "against: gemini-pro_full | test_loss: 0.2290 | test_acc: 92.4328 | test_f1: 0.9509 | test_brier: 0.0606 | time: 63.7829\n",
      "against: gpt-3.5-turbo-0125_30_percent | test_loss: 0.4900 | test_acc: 89.2966 | test_f1: 0.8997 | test_brier: 0.0854 | time: 28.0571\n",
      "against: gpt-3.5-turbo-0125_full | test_loss: 0.2700 | test_acc: 93.4229 | test_f1: 0.9577 | test_brier: 0.0491 | time: 55.3491\n",
      "against: gpt-4-turbo-preview_30_percent | test_loss: 0.2693 | test_acc: 90.3670 | test_f1: 0.9106 | test_brier: 0.0750 | time: 30.2286\n",
      "against: gpt-4-turbo-preview_full | test_loss: 0.1416 | test_acc: 94.9081 | test_f1: 0.9675 | test_brier: 0.0389 | time: 68.9446\n",
      "against: meta-llama-llama-2-70b-chat-hf_30_percent | test_loss: 0.2867 | test_acc: 90.0612 | test_f1: 0.9075 | test_brier: 0.0796 | time: 32.2095\n",
      "against: meta-llama-llama-2-70b-chat-hf_full | test_loss: 0.1442 | test_acc: 94.8373 | test_f1: 0.9670 | test_brier: 0.0396 | time: 67.6867\n",
      "against: meta-llama-llama-2-7b-chat-hf_30_percent | test_loss: 0.3446 | test_acc: 88.8379 | test_f1: 0.8950 | test_brier: 0.0905 | time: 30.3500\n",
      "against: meta-llama-llama-2-7b-chat-hf_full | test_loss: 0.2281 | test_acc: 93.7058 | test_f1: 0.9595 | test_brier: 0.0504 | time: 59.7226\n",
      "against: mistralai-mixtral-8x7b-instruct-v0.1_30_percent | test_loss: 0.3097 | test_acc: 89.2966 | test_f1: 0.8997 | test_brier: 0.0848 | time: 32.7760\n",
      "against: mistralai-mixtral-8x7b-instruct-v0.1_full | test_loss: 0.1822 | test_acc: 94.0594 | test_f1: 0.9619 | test_brier: 0.0480 | time: 68.9667\n",
      "against: qwen-qwen1.5-72b-chat-8bit_30_percent | test_loss: 0.2579 | test_acc: 90.8257 | test_f1: 0.9157 | test_brier: 0.0720 | time: 28.0425\n",
      "against: qwen-qwen1.5-72b-chat-8bit_full | test_loss: 0.1232 | test_acc: 95.6860 | test_f1: 0.9727 | test_brier: 0.0338 | time: 48.2027\n",
      "against: text-bison-002_30_percent | test_loss: 5.2662 | test_acc: 89.1437 | test_f1: 0.8981 | test_brier: 0.0857 | time: 31.9597\n",
      "against: text-bison-002_full | test_loss: 2.5295 | test_acc: 94.3423 | test_f1: 0.9638 | test_brier: 0.0446 | time: 66.6776\n",
      "against: vicgalle-gpt2-open-instruct-v1_30_percent | test_loss: 0.8956 | test_acc: 84.0979 | test_f1: 0.8443 | test_brier: 0.1279 | time: 26.6510\n",
      "against: vicgalle-gpt2-open-instruct-v1_full | test_loss: 0.7169 | test_acc: 84.7949 | test_f1: 0.8965 | test_brier: 0.1227 | time: 47.9830\n",
      "Finished testing against all LLms for mistralai-mistral-7b-instruct-v0.2\n",
      "Testing against all LLMs for mistralai-mixtral-8x7b-instruct-v0.1...\n",
      "against: alpaca-7b_30_percent | test_loss: 6.2970 | test_acc: 63.4557 | test_f1: 0.4816 | test_brier: 0.3145 | time: 25.6963\n",
      "against: alpaca-7b_full | test_loss: 10.7094 | test_acc: 53.5361 | test_f1: 0.5797 | test_brier: 0.4081 | time: 42.5952\n",
      "against: bigscience-bloomz-7b1_30_percent | test_loss: 1.6995 | test_acc: 58.2569 | test_f1: 0.3607 | test_brier: 0.3628 | time: 27.0346\n",
      "against: bigscience-bloomz-7b1_full | test_loss: 2.4097 | test_acc: 36.7044 | test_f1: 0.3245 | test_brier: 0.5455 | time: 46.2332\n",
      "against: chavinlo-alpaca-13b_30_percent | test_loss: 5.6893 | test_acc: 65.4434 | test_f1: 0.5232 | test_brier: 0.3182 | time: 26.1448\n",
      "against: chavinlo-alpaca-13b_full | test_loss: 8.3073 | test_acc: 56.2942 | test_f1: 0.6142 | test_brier: 0.3955 | time: 49.1091\n",
      "against: gemini-pro_30_percent | test_loss: 0.4759 | test_acc: 83.0275 | test_f1: 0.8115 | test_brier: 0.1310 | time: 32.1516\n",
      "against: gemini-pro_full | test_loss: 0.4953 | test_acc: 81.3296 | test_f1: 0.8650 | test_brier: 0.1389 | time: 63.5858\n",
      "against: gpt-3.5-turbo-0125_30_percent | test_loss: 0.2994 | test_acc: 94.3425 | test_f1: 0.9442 | test_brier: 0.0463 | time: 28.0204\n",
      "against: gpt-3.5-turbo-0125_full | test_loss: 0.2188 | test_acc: 94.4837 | test_f1: 0.9636 | test_brier: 0.0435 | time: 54.1136\n",
      "against: gpt-4-turbo-preview_30_percent | test_loss: 0.1608 | test_acc: 94.3425 | test_f1: 0.9440 | test_brier: 0.0441 | time: 31.5795\n",
      "against: gpt-4-turbo-preview_full | test_loss: 0.1079 | test_acc: 96.4639 | test_f1: 0.9770 | test_brier: 0.0295 | time: 67.8951\n",
      "against: meta-llama-llama-2-70b-chat-hf_30_percent | test_loss: 0.2714 | test_acc: 90.8257 | test_f1: 0.9062 | test_brier: 0.0749 | time: 32.0117\n",
      "against: meta-llama-llama-2-70b-chat-hf_full | test_loss: 0.1951 | test_acc: 93.1400 | test_f1: 0.9543 | test_brier: 0.0531 | time: 62.1772\n",
      "against: meta-llama-llama-2-7b-chat-hf_30_percent | test_loss: 0.3069 | test_acc: 88.8379 | test_f1: 0.8836 | test_brier: 0.0858 | time: 29.4833\n",
      "against: meta-llama-llama-2-7b-chat-hf_full | test_loss: 0.3053 | test_acc: 90.0990 | test_f1: 0.9327 | test_brier: 0.0784 | time: 60.3283\n",
      "against: mistralai-mistral-7b-instruct-v0.2_30_percent | test_loss: 0.2714 | test_acc: 90.6728 | test_f1: 0.9042 | test_brier: 0.0733 | time: 31.5621\n",
      "against: mistralai-mistral-7b-instruct-v0.2_full | test_loss: 0.2256 | test_acc: 91.3720 | test_f1: 0.9418 | test_brier: 0.0645 | time: 69.9576\n",
      "against: qwen-qwen1.5-72b-chat-8bit_30_percent | test_loss: 0.1560 | test_acc: 94.8012 | test_f1: 0.9489 | test_brier: 0.0424 | time: 27.0350\n",
      "against: qwen-qwen1.5-72b-chat-8bit_full | test_loss: 0.1005 | test_acc: 96.7468 | test_f1: 0.9788 | test_brier: 0.0260 | time: 47.9385\n",
      "against: text-bison-002_30_percent | test_loss: 4.2379 | test_acc: 91.8960 | test_f1: 0.9181 | test_brier: 0.0653 | time: 29.6593\n",
      "against: text-bison-002_full | test_loss: 2.1002 | test_acc: 93.6351 | test_f1: 0.9577 | test_brier: 0.0515 | time: 62.0229\n",
      "against: vicgalle-gpt2-open-instruct-v1_30_percent | test_loss: 0.8426 | test_acc: 81.6514 | test_f1: 0.7931 | test_brier: 0.1488 | time: 29.2814\n",
      "against: vicgalle-gpt2-open-instruct-v1_full | test_loss: 0.8149 | test_acc: 74.5403 | test_f1: 0.8065 | test_brier: 0.1930 | time: 46.4179\n",
      "Finished testing against all LLms for mistralai-mixtral-8x7b-instruct-v0.1\n",
      "Testing against all LLMs for qwen-qwen1.5-72b-chat-8bit...\n",
      "against: alpaca-7b_30_percent | test_loss: 1.1879 | test_acc: 73.8532 | test_f1: 0.6667 | test_brier: 0.2284 | time: 24.3741\n",
      "against: alpaca-7b_full | test_loss: 1.6405 | test_acc: 62.4470 | test_f1: 0.6826 | test_brier: 0.3282 | time: 38.9970\n",
      "against: bigscience-bloomz-7b1_30_percent | test_loss: 2.4632 | test_acc: 54.8930 | test_f1: 0.2416 | test_brier: 0.4199 | time: 23.4060\n",
      "against: bigscience-bloomz-7b1_full | test_loss: 3.6706 | test_acc: 31.7539 | test_f1: 0.2211 | test_brier: 0.6377 | time: 42.9186\n",
      "against: chavinlo-alpaca-13b_30_percent | test_loss: 1.2780 | test_acc: 73.2416 | test_f1: 0.6562 | test_brier: 0.2400 | time: 24.9348\n",
      "against: chavinlo-alpaca-13b_full | test_loss: 1.5810 | test_acc: 63.6492 | test_f1: 0.6959 | test_brier: 0.3187 | time: 44.1495\n",
      "against: gemini-pro_30_percent | test_loss: 0.5797 | test_acc: 83.3333 | test_f1: 0.8104 | test_brier: 0.1311 | time: 29.0133\n",
      "against: gemini-pro_full | test_loss: 0.6480 | test_acc: 78.6421 | test_f1: 0.8412 | test_brier: 0.1685 | time: 60.2626\n",
      "against: gpt-3.5-turbo-0125_30_percent | test_loss: 0.3162 | test_acc: 90.9786 | test_f1: 0.9056 | test_brier: 0.0674 | time: 27.8380\n",
      "against: gpt-3.5-turbo-0125_full | test_loss: 0.2866 | test_acc: 90.5233 | test_f1: 0.9353 | test_brier: 0.0713 | time: 58.2552\n",
      "against: gpt-4-turbo-preview_30_percent | test_loss: 0.2054 | test_acc: 95.5657 | test_f1: 0.9557 | test_brier: 0.0351 | time: 28.9858\n",
      "against: gpt-4-turbo-preview_full | test_loss: 0.1510 | test_acc: 96.0396 | test_f1: 0.9739 | test_brier: 0.0307 | time: 62.0623\n",
      "against: meta-llama-llama-2-70b-chat-hf_30_percent | test_loss: 0.3011 | test_acc: 91.5902 | test_f1: 0.9126 | test_brier: 0.0629 | time: 29.4983\n",
      "against: meta-llama-llama-2-70b-chat-hf_full | test_loss: 0.3344 | test_acc: 89.3211 | test_f1: 0.9264 | test_brier: 0.0822 | time: 59.9428\n",
      "against: meta-llama-llama-2-7b-chat-hf_30_percent | test_loss: 0.3674 | test_acc: 89.6024 | test_f1: 0.8896 | test_brier: 0.0806 | time: 28.6047\n",
      "against: meta-llama-llama-2-7b-chat-hf_full | test_loss: 0.3919 | test_acc: 87.5530 | test_f1: 0.9132 | test_brier: 0.0995 | time: 57.7965\n",
      "against: mistralai-mistral-7b-instruct-v0.2_30_percent | test_loss: 0.3734 | test_acc: 88.8379 | test_f1: 0.8805 | test_brier: 0.0864 | time: 29.8616\n",
      "against: mistralai-mistral-7b-instruct-v0.2_full | test_loss: 0.3998 | test_acc: 85.5728 | test_f1: 0.8980 | test_brier: 0.1085 | time: 63.0540\n",
      "against: mistralai-mixtral-8x7b-instruct-v0.1_30_percent | test_loss: 0.3828 | test_acc: 88.2263 | test_f1: 0.8731 | test_brier: 0.0872 | time: 29.6813\n",
      "against: mistralai-mixtral-8x7b-instruct-v0.1_full | test_loss: 0.4054 | test_acc: 85.2900 | test_f1: 0.8958 | test_brier: 0.1090 | time: 61.0395\n",
      "against: text-bison-002_30_percent | test_loss: 0.3349 | test_acc: 90.8257 | test_f1: 0.9038 | test_brier: 0.0705 | time: 27.5248\n",
      "against: text-bison-002_full | test_loss: 0.3267 | test_acc: 89.8868 | test_f1: 0.9306 | test_brier: 0.0815 | time: 58.4018\n",
      "against: vicgalle-gpt2-open-instruct-v1_30_percent | test_loss: 1.4900 | test_acc: 67.1254 | test_f1: 0.5416 | test_brier: 0.2920 | time: 22.9335\n",
      "against: vicgalle-gpt2-open-instruct-v1_full | test_loss: 2.1100 | test_acc: 52.1216 | test_f1: 0.5566 | test_brier: 0.4215 | time: 46.8983\n",
      "Finished testing against all LLms for qwen-qwen1.5-72b-chat-8bit\n",
      "Testing against all LLMs for text-bison-002...\n",
      "against: alpaca-7b_30_percent | test_loss: 7.1432 | test_acc: 70.1835 | test_f1: 0.5996 | test_brier: 0.2736 | time: 23.2377\n",
      "against: alpaca-7b_full | test_loss: 12.0147 | test_acc: 58.9109 | test_f1: 0.6416 | test_brier: 0.3790 | time: 39.2497\n",
      "against: bigscience-bloomz-7b1_30_percent | test_loss: 1.9961 | test_acc: 58.5627 | test_f1: 0.3406 | test_brier: 0.3686 | time: 23.9958\n",
      "against: bigscience-bloomz-7b1_full | test_loss: 2.7730 | test_acc: 37.0580 | test_f1: 0.3216 | test_brier: 0.5598 | time: 42.8786\n",
      "against: chavinlo-alpaca-13b_30_percent | test_loss: 6.6481 | test_acc: 66.2080 | test_f1: 0.5206 | test_brier: 0.3161 | time: 25.3580\n",
      "against: chavinlo-alpaca-13b_full | test_loss: 9.9074 | test_acc: 53.3946 | test_f1: 0.5729 | test_brier: 0.4381 | time: 43.6955\n",
      "against: gemini-pro_30_percent | test_loss: 0.3784 | test_acc: 88.8379 | test_f1: 0.8797 | test_brier: 0.0934 | time: 31.1192\n",
      "against: gemini-pro_full | test_loss: 0.3802 | test_acc: 88.4017 | test_f1: 0.9194 | test_brier: 0.0962 | time: 62.7425\n",
      "against: gpt-3.5-turbo-0125_30_percent | test_loss: 0.3409 | test_acc: 93.8838 | test_f1: 0.9375 | test_brier: 0.0496 | time: 30.7316\n",
      "against: gpt-3.5-turbo-0125_full | test_loss: 0.2399 | test_acc: 94.5545 | test_f1: 0.9638 | test_brier: 0.0441 | time: 53.8561\n",
      "against: gpt-4-turbo-preview_30_percent | test_loss: 0.1007 | test_acc: 96.9419 | test_f1: 0.9697 | test_brier: 0.0246 | time: 29.1686\n",
      "against: gpt-4-turbo-preview_full | test_loss: 0.0749 | test_acc: 97.3833 | test_f1: 0.9829 | test_brier: 0.0204 | time: 60.3356\n",
      "against: meta-llama-llama-2-70b-chat-hf_30_percent | test_loss: 0.2200 | test_acc: 93.2722 | test_f1: 0.9308 | test_brier: 0.0564 | time: 29.7274\n",
      "against: meta-llama-llama-2-70b-chat-hf_full | test_loss: 0.1915 | test_acc: 93.2107 | test_f1: 0.9544 | test_brier: 0.0528 | time: 60.0615\n",
      "against: meta-llama-llama-2-7b-chat-hf_30_percent | test_loss: 0.3596 | test_acc: 88.8379 | test_f1: 0.8797 | test_brier: 0.0865 | time: 27.7000\n",
      "against: meta-llama-llama-2-7b-chat-hf_full | test_loss: 0.3768 | test_acc: 88.4724 | test_f1: 0.9200 | test_brier: 0.0896 | time: 55.6056\n",
      "against: mistralai-mistral-7b-instruct-v0.2_30_percent | test_loss: 0.3077 | test_acc: 90.3670 | test_f1: 0.8979 | test_brier: 0.0817 | time: 30.0159\n",
      "against: mistralai-mistral-7b-instruct-v0.2_full | test_loss: 0.3244 | test_acc: 89.0382 | test_f1: 0.9242 | test_brier: 0.0880 | time: 63.3213\n",
      "against: mistralai-mixtral-8x7b-instruct-v0.1_30_percent | test_loss: 0.3197 | test_acc: 90.5199 | test_f1: 0.8997 | test_brier: 0.0791 | time: 29.6836\n",
      "against: mistralai-mixtral-8x7b-instruct-v0.1_full | test_loss: 0.3084 | test_acc: 89.8161 | test_f1: 0.9300 | test_brier: 0.0808 | time: 62.4804\n",
      "against: qwen-qwen1.5-72b-chat-8bit_30_percent | test_loss: 0.1572 | test_acc: 94.6483 | test_f1: 0.9459 | test_brier: 0.0433 | time: 33.4935\n",
      "against: qwen-qwen1.5-72b-chat-8bit_full | test_loss: 0.1169 | test_acc: 95.6153 | test_f1: 0.9710 | test_brier: 0.0330 | time: 55.2404\n",
      "against: vicgalle-gpt2-open-instruct-v1_30_percent | test_loss: 0.8576 | test_acc: 83.6391 | test_f1: 0.8139 | test_brier: 0.1372 | time: 23.7485\n",
      "against: vicgalle-gpt2-open-instruct-v1_full | test_loss: 0.8547 | test_acc: 77.3692 | test_f1: 0.8300 | test_brier: 0.1863 | time: 43.3986\n",
      "Finished testing against all LLms for text-bison-002\n",
      "Testing against all LLMs for vicgalle-gpt2-open-instruct-v1...\n",
      "against: alpaca-7b_30_percent | test_loss: 3.0151 | test_acc: 84.8624 | test_f1: 0.8260 | test_brier: 0.1485 | time: 22.3304\n",
      "against: alpaca-7b_full | test_loss: 4.4434 | test_acc: 76.8741 | test_f1: 0.8243 | test_brier: 0.2252 | time: 39.7245\n",
      "against: bigscience-bloomz-7b1_30_percent | test_loss: 3.6288 | test_acc: 64.8318 | test_f1: 0.4749 | test_brier: 0.3331 | time: 24.0729\n",
      "against: bigscience-bloomz-7b1_full | test_loss: 5.2686 | test_acc: 47.1711 | test_f1: 0.4816 | test_brier: 0.5046 | time: 43.8828\n",
      "against: chavinlo-alpaca-13b_30_percent | test_loss: 3.9199 | test_acc: 83.7920 | test_f1: 0.8114 | test_brier: 0.1581 | time: 25.4202\n",
      "against: chavinlo-alpaca-13b_full | test_loss: 4.8524 | test_acc: 76.3791 | test_f1: 0.8198 | test_brier: 0.2295 | time: 43.5583\n",
      "against: gemini-pro_30_percent | test_loss: 3.7899 | test_acc: 57.0336 | test_f1: 0.2739 | test_brier: 0.4076 | time: 29.0278\n",
      "against: gemini-pro_full | test_loss: 5.5901 | test_acc: 34.4413 | test_f1: 0.2649 | test_brier: 0.6229 | time: 58.8154\n",
      "against: gpt-3.5-turbo-0125_30_percent | test_loss: 2.4731 | test_acc: 66.9725 | test_f1: 0.5221 | test_brier: 0.3069 | time: 25.1493\n",
      "against: gpt-3.5-turbo-0125_full | test_loss: 3.7951 | test_acc: 47.8784 | test_f1: 0.4921 | test_brier: 0.4843 | time: 50.3058\n",
      "against: gpt-4-turbo-preview_30_percent | test_loss: 3.3041 | test_acc: 56.5749 | test_f1: 0.2604 | test_brier: 0.4024 | time: 28.3886\n",
      "against: gpt-4-turbo-preview_full | test_loss: 4.6345 | test_acc: 34.6535 | test_f1: 0.2690 | test_brier: 0.6065 | time: 60.2200\n",
      "against: meta-llama-llama-2-70b-chat-hf_30_percent | test_loss: 2.3940 | test_acc: 62.8440 | test_f1: 0.4282 | test_brier: 0.3318 | time: 29.5108\n",
      "against: meta-llama-llama-2-70b-chat-hf_full | test_loss: 3.4769 | test_acc: 41.8670 | test_f1: 0.3982 | test_brier: 0.5251 | time: 59.2963\n",
      "against: meta-llama-llama-2-7b-chat-hf_30_percent | test_loss: 3.0265 | test_acc: 63.6086 | test_f1: 0.4465 | test_brier: 0.3441 | time: 28.5619\n",
      "against: meta-llama-llama-2-7b-chat-hf_full | test_loss: 4.2167 | test_acc: 42.6450 | test_f1: 0.4110 | test_brier: 0.5326 | time: 55.3697\n",
      "against: mistralai-mistral-7b-instruct-v0.2_30_percent | test_loss: 3.2034 | test_acc: 60.5505 | test_f1: 0.3707 | test_brier: 0.3710 | time: 29.4298\n",
      "against: mistralai-mistral-7b-instruct-v0.2_full | test_loss: 4.8271 | test_acc: 36.2093 | test_f1: 0.2986 | test_brier: 0.5949 | time: 64.1092\n",
      "against: mistralai-mixtral-8x7b-instruct-v0.1_30_percent | test_loss: 3.2246 | test_acc: 59.4801 | test_f1: 0.3424 | test_brier: 0.3811 | time: 29.7088\n",
      "against: mistralai-mixtral-8x7b-instruct-v0.1_full | test_loss: 4.5817 | test_acc: 36.0679 | test_f1: 0.2960 | test_brier: 0.5968 | time: 61.0964\n",
      "against: qwen-qwen1.5-72b-chat-8bit_30_percent | test_loss: 2.6936 | test_acc: 55.3517 | test_f1: 0.2234 | test_brier: 0.4155 | time: 29.6889\n",
      "against: qwen-qwen1.5-72b-chat-8bit_full | test_loss: 3.7840 | test_acc: 31.8953 | test_f1: 0.2139 | test_brier: 0.6379 | time: 44.6603\n",
      "against: text-bison-002_30_percent | test_loss: 2.4865 | test_acc: 61.7737 | test_f1: 0.4019 | test_brier: 0.3495 | time: 28.3225\n",
      "against: text-bison-002_full | test_loss: 3.5520 | test_acc: 43.1400 | test_f1: 0.4191 | test_brier: 0.5183 | time: 61.0605\n",
      "Finished testing against all LLms for vicgalle-gpt2-open-instruct-v1\n"
     ]
    }
   ],
   "source": [
    "final_results = []\n",
    "\n",
    "for llm_name in df['dataset_name'].unique():\n",
    "    if llm_name == Path(HUMAN_JSON_FILE_NAME).stem:\n",
    "        continue\n",
    "    \n",
    "    model_path = f'{BASELINE_MODELS_FOLDER_PATH}/{llm_name}.pt'\n",
    "\n",
    "    model = RNN(tokenizer.vocab_size, EMBEDDING_SIZE, LSTM_UNITS, LSTM_LAYERS, device, dropout=0.6).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    print(f'Testing against all LLMs for {llm_name}...')\n",
    "\n",
    "    results = test_against_all(\n",
    "        model=model,\n",
    "        trained_llm_name=llm_name,\n",
    "        human_test_df=human_test_df,\n",
    "        df=df,\n",
    "        loss_fn=loss_fn,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    final_results.append({\n",
    "        'base_model': llm_name,\n",
    "        'results_against_all_llms': results\n",
    "    })\n",
    "\n",
    "    print(f'Finished testing against all LLms for {llm_name}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a JSON Encoder class\n",
    "class json_serialize(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "    \n",
    "with open('../../data/baseline/results/one_vs_all.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(final_results, f, ensure_ascii=False, indent=4, cls=json_serialize)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-detect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
