{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MA61uwS740Q"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "iCE3kpB4740T"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import json\n",
        "import os\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from timeit import default_timer as timer\n",
        "from os import walk\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, roc_curve, auc, brier_score_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTF_l6oL740U"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "2PNl6pFm740V"
      },
      "outputs": [],
      "source": [
        "ROOT_DATA = './'\n",
        "ROOT_DATA_RAW = f'{ROOT_DATA}'\n",
        "HUMAN_JSON_FILE_NAME = 'human.jsonl'\n",
        "HUMAN_JSON_PATH = f'{ROOT_DATA_RAW}/{HUMAN_JSON_FILE_NAME}'\n",
        "MODELS_JSON_FOLDER_PATH = f'{ROOT_DATA_RAW}/machines'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KCwuqvLK740V"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "LSTM_UNITS = 256\n",
        "LSTM_LAYERS = 5\n",
        "EMBEDDING_SIZE = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "DXcVdldo740V"
      },
      "outputs": [],
      "source": [
        "TEST_SET_FRACTION = 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OQnIFWZs740W"
      },
      "outputs": [],
      "source": [
        "df = pd.read_json(path_or_buf=HUMAN_JSON_PATH, lines=True)\n",
        "df['text_index'] = df.index\n",
        "df['is_llm'] = 0\n",
        "df['dataset_name'] = Path(HUMAN_JSON_FILE_NAME).stem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "A0g2lLoQ740W"
      },
      "outputs": [],
      "source": [
        "dir_path, dir_names, file_names = next(walk(MODELS_JSON_FOLDER_PATH))\n",
        "\n",
        "for file_name in file_names:\n",
        "    temp_df = pd.read_json(path_or_buf=f'{MODELS_JSON_FOLDER_PATH}/{file_name}', lines=True)\n",
        "    temp_df['text_index'] = temp_df.index\n",
        "    temp_df['is_llm'] = 1\n",
        "    temp_df['dataset_name'] = Path(file_name).stem\n",
        "\n",
        "    df = pd.concat([df, temp_df], ignore_index=True)\n",
        "\n",
        "df.drop(labels=['id'], inplace=True, axis='columns')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "0HxsOsvP740W",
        "outputId": "98ef28b2-2c3e-4f80-b911-94919e85f86b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"MISSING: Gabby Petito, 22, Last Seen Traveling Through Utah and Wyoming\\n\\nSALT LAKE CITY \\u2013 Authorities are actively searching for Gabby Petito, a 22-year-old woman from Blue Point, New York, who was last seen traveling through Utah and Wyoming with her boyfriend.\\n\\nGabby and her boyfriend embarked on a cross-country trip on July 2, documenting their adventures on social media. They visited popular destinations such as Colorado, Southern Utah, Arches National Park, and Canyonlands National Park. However, Petito's Instagram posts slowed down towards the end of August, with the last communication on August 30 being uncertain.\\n\\nThe last known location of Petito was Salt Lake City on August 21, confirmed through an Uber Eats order placed by her father, Joseph Petito. \\\"We know she was here in Salt Lake City, but after that, we don't know where she went,\\\" Joseph said in an interview.\\n\\nPetito's parents believe the couple left Salt Lake City for Grand Teton National Park around August 24, spending no more than two days there. However, communication between Petito and her mother, Nichole Schmidt, became sporadic after August 24, with the nature of Petito's relationship with her boyfriend in question.\\n\\n\\\"We're worried sick. We just want to know where she is and that she's safe,\\\" Schmidt said, her voice trembling with concern.\\n\\nThe Suffolk County Police Department has confirmed the retrieval of the van used by the couple, but they have provided no information on the boyfriend's whereabouts. A case has officially been opened by the Suffolk County Police Department, and the public is urged to provide information.\\n\\n\\\"We're asking for anyone who may have seen Gabby or her boyfriend to come forward and share any information they may have,\\\" said a spokesperson for the Suffolk County Police Department.\\n\\nPetito's parents have established a Facebook page for updates and a GoFundMe page to help with expenses. \\\"We're grateful for any help we can get. We just want Gabby back safe and sound,\\\" Schmidt said.\\n\\nThe disappearance of Gabby Petito has sent shockwaves through the community, with many people sharing her story and offering support to her family. \\\"We're grateful for the outpouring of support and concern. We're hopeful that Gabby will be found soon,\\\" Joseph said.\\n\\nAs the search for Gabby Petito continues, authorities are urging anyone with information to come forward. \\\"We're working tirelessly to find Gabby and bring her home safely. We need the public's help to make that happen,\\\" the spokesperson for the Suffolk County Police Department said.\\n\\nThe case of Gabby Petito's disappearance remains a mystery, with many questions still unanswered. One thing is certain, however: her family and friends are desperate for answers and are holding onto hope that she will be found soon.\\n\\nAnyone with information regarding Gabby Petito's whereabouts is urged to contact the Suffolk County Police Department at (631) 852-6000.\",\n          \"Gabby Petito Remembered as 'Super Kind-Hearted' by Surf Shop Owner as Search for Brian Laundrie Continues\\n\\nGabby Petito, the 22-year-old woman who was found dead in Wyoming's Teton-Bridger National Forest, was remembered by a surf shop owner in her Long Island hometown as a \\\"super kind-hearted, sweet girl.\\\" The surf shop owner, who wished to remain anonymous, spoke to Fox News about Petito's friendly demeanor and love for the outdoors.\\n\\n\\\"Gabby was a longtime customer of ours, and she was always smiling,\\\" the surf shop owner said. \\\"She had a passion for surfing and the beach, and she was always eager to share her adventures with us. She was a super kind-hearted, sweet girl, and we're all devastated by her loss.\\\"\\n\\nPetito's remains were found on September 21, and her death was ruled a homicide by the Teton County Coroner. She had been missing since September 1, when her fianc\\u00e9, Brian Laundrie, returned to Florida without her. Laundrie has been named a person of interest in Petito's disappearance and is currently being sought by authorities.\\n\\nPetito and Laundrie had embarked on a cross-country road trip in June, traveling from Florida to New York and then towards western national parks. They visited the surf shop in early July, where Petito bought a shirt for Laundrie.\\n\\n\\\"Gabby was so excited to be on this trip and to explore the country,\\\" the surf shop owner said. \\\"She was always talking about how much she loved the outdoors and how she wanted to live life to the fullest. She was such a creative and artistic person, and she had a spark in her eye that was just infectious.\\\"\\n\\nPetito's white van was seized from Laundrie's family home on September 11, and authorities are currently searching for Laundrie in a Florida nature reserve and other locations.\\n\\nNichole Schmidt, Petito's mother, spoke to Fox News about her daughter's love for adventure and her desire to explore the world.\\n\\n\\\"Gabby was always a free spirit, and she loved to try new things,\\\" Schmidt said. \\\"She was always up for an adventure, and she had a heart of gold. She was the kind of person who would go out of her way to help someone in need, and she had a smile that could light up a room.\\\"\\n\\nSchmidt also expressed her gratitude for the support her family has received during this difficult time.\\n\\n\\\"We're so grateful for the outpouring of love and support we've received from the community,\\\" Schmidt said. \\\"Gabby was a special person, and she touched so many lives. We're just trying to stay strong and keep her memory alive.\\\"\\n\\nAs the search for Laundrie continues, the surf shop owner echoed Schmidt's sentiments, saying that Petito's memory will live on through the countless lives she touched.\\n\\n\\\"Gabby was a shining light, and she left a mark on everyone she met,\\\" the surf shop owner said. \\\"We're all better for having known her, and we'll never forget her spirit and her love for life.\\\"\",\n          \"UW Oshkosh Student Claims Giving Ride to Brian Laundrie in Grand Teton National Park\\n\\nWYOMING (WBAY) \\u2013 A University of Wisconsin Oshkosh student, Miranda Baker, has come forward with a startling revelation that she and her boyfriend gave a ride to Brian Laundrie, a person of interest in the Gabby Petito case, in Grand Teton National Park on August 29.\\n\\nBaker shared her experience on TikTok, which prompted her to contact authorities to assist with the investigation. According to Baker, Laundrie offered to pay $200 for a ride for what would be a 10-mile journey, which she found odd.\\n\\n\\\"He said he had been camping for several days without his fianc\\u00e9e, who was working on their social media page back at their van,\\\" Baker said in her TikTok video.\\n\\nWhen Baker mentioned they were heading to Jackson, Laundrie urgently requested to be let out of the vehicle. Laundrie was last seen by Baker at around 6:09 p.m. on August 29, seeking another ride at Jackson Dam, near Colter Bay.\\n\\nLaundrie returned to his home in North Port, Florida, on September 1, while Gabby Petito's family reported her missing on September 11. Laundrie has not cooperated with authorities in the investigation.\\n\\nThe development comes after a domestic violence incident involving Petito and Laundrie was reported in Utah on August 12, captured on bodycam footage, with no charges filed.\\n\\nBaker's revelation has sparked renewed interest in the case, with many questioning Laundrie's involvement in Petito's disappearance and death.\\n\\n\\\"I just wanted to share my experience because I saw him on the news and I was like, 'Wait a minute, that's the guy we picked up,'\\\" Baker said in her TikTok video.\\n\\nThe FBI and local authorities have been investigating Petito's disappearance and death, with Laundrie identified as a person of interest.\\n\\nPetito's body was believed to have been found on September 19, sparking a nationwide search for Laundrie.\\n\\nAs the investigation continues, Baker's account has raised questions about Laundrie's whereabouts and activities in the days leading up to Petito's disappearance.\\n\\nThe case has gripped the nation, with many calling for justice for Gabby Petito.\\n\\nIn the wake of Baker's revelation, authorities are urging anyone with information about Laundrie's whereabouts or activities to come forward.\\n\\nThe investigation into Gabby Petito's disappearance and death continues, with Brian Laundrie remaining a person of interest.\\n\\nAs the search for answers continues, Miranda Baker's account serves as a reminder of the importance of vigilance and the role that ordinary citizens can play in solving crimes.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1082,\n        \"max\": 1086,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1083,\n          1086,\n          1084\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_llm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dataset_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"meta-llama-llama-2-70b-chat-hf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a9c64e3c-3b40-4f80-b500-54333dd7b288\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_index</th>\n",
              "      <th>is_llm</th>\n",
              "      <th>dataset_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15213</th>\n",
              "      <td>Gabby Petito's Disappearance: How Social Media...</td>\n",
              "      <td>1082</td>\n",
              "      <td>1</td>\n",
              "      <td>meta-llama-llama-2-70b-chat-hf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15214</th>\n",
              "      <td>MISSING: Gabby Petito, 22, Last Seen Traveling...</td>\n",
              "      <td>1083</td>\n",
              "      <td>1</td>\n",
              "      <td>meta-llama-llama-2-70b-chat-hf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15215</th>\n",
              "      <td>UW Oshkosh Student Claims Giving Ride to Brian...</td>\n",
              "      <td>1084</td>\n",
              "      <td>1</td>\n",
              "      <td>meta-llama-llama-2-70b-chat-hf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15216</th>\n",
              "      <td>The Gabby Petito Case: How Social Media Shaped...</td>\n",
              "      <td>1085</td>\n",
              "      <td>1</td>\n",
              "      <td>meta-llama-llama-2-70b-chat-hf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15217</th>\n",
              "      <td>Gabby Petito Remembered as 'Super Kind-Hearted...</td>\n",
              "      <td>1086</td>\n",
              "      <td>1</td>\n",
              "      <td>meta-llama-llama-2-70b-chat-hf</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9c64e3c-3b40-4f80-b500-54333dd7b288')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a9c64e3c-3b40-4f80-b500-54333dd7b288 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a9c64e3c-3b40-4f80-b500-54333dd7b288');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5895c3f0-791d-45e7-a587-e25e9151d85b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5895c3f0-791d-45e7-a587-e25e9151d85b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5895c3f0-791d-45e7-a587-e25e9151d85b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                    text  text_index  is_llm  \\\n",
              "15213  Gabby Petito's Disappearance: How Social Media...        1082       1   \n",
              "15214  MISSING: Gabby Petito, 22, Last Seen Traveling...        1083       1   \n",
              "15215  UW Oshkosh Student Claims Giving Ride to Brian...        1084       1   \n",
              "15216  The Gabby Petito Case: How Social Media Shaped...        1085       1   \n",
              "15217  Gabby Petito Remembered as 'Super Kind-Hearted...        1086       1   \n",
              "\n",
              "                         dataset_name  \n",
              "15213  meta-llama-llama-2-70b-chat-hf  \n",
              "15214  meta-llama-llama-2-70b-chat-hf  \n",
              "15215  meta-llama-llama-2-70b-chat-hf  \n",
              "15216  meta-llama-llama-2-70b-chat-hf  \n",
              "15217  meta-llama-llama-2-70b-chat-hf  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcIOvBIN740Y"
      },
      "source": [
        "### Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "VPWyPTQf740Y"
      },
      "outputs": [],
      "source": [
        "checkpoint = 'distilbert-base-cased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jydpqlS5740Y",
        "outputId": "112501fa-b1c2-4bdf-cab5-980a19c28745"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (843 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "df['tokenized_text'] = tokenizer(list(df['text'].to_list()))['input_ids']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC6CoiQi740Z"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4rv8Eyu740Z",
        "outputId": "c8bf2986-f1fa-4b7b-f138-f42b75343f8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "pYw9bUeF740Z"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size, layers_num, device, output_size=1, dropout=0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.layers_num = layers_num\n",
        "        self.output_size= output_size\n",
        "        self.dropout = dropout\n",
        "        self.device = device\n",
        "\n",
        "        self.embed = nn.Embedding(self.vocab_size, self.embedding_size, device=self.device)\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.embedding_size,\n",
        "            hidden_size=self.hidden_size,\n",
        "            num_layers=self.layers_num,\n",
        "            batch_first=True,\n",
        "            dropout=self.dropout,\n",
        "            device=self.device\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(\n",
        "            self.hidden_size,\n",
        "            self.output_size\n",
        "        )\n",
        "\n",
        "    def forward(self, X, lengths):\n",
        "        embeddings = self.embed(X)\n",
        "\n",
        "        seq_output, (h_n, c_n) = self.lstm(embeddings)\n",
        "\n",
        "        out = seq_output.sum(dim=1).div(lengths.float().unsqueeze(dim=1))\n",
        "        logits = self.fc(out)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEMs0pPw740a"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "vaNb5eVe740a"
      },
      "outputs": [],
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (\n",
        "            self.X.to_numpy()[index],\n",
        "            self.y.to_numpy()[index]\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "eds7J8-V740a"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "  # We want to sort the batch by seq length,\n",
        "  # in order to make the computation more efficient\n",
        "  batch = sorted(batch, key=lambda x: len(x[0]), reverse=True)\n",
        "\n",
        "  inputs = [torch.LongTensor(x[0]).to(device) for x in batch]\n",
        "  padded_input = nn.utils.rnn.pad_sequence(inputs, batch_first=True)\n",
        "\n",
        "  lengths = torch.LongTensor([len(x[0]) for x in batch]).to(device)\n",
        "\n",
        "  y = torch.FloatTensor(np.array([x[1] for x in batch])).reshape(-1, 1).to(device)\n",
        "\n",
        "  return padded_input, lengths, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQxqO-qa740a"
      },
      "source": [
        "## Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "NwsSKKI9740b"
      },
      "outputs": [],
      "source": [
        "X, y = df['tokenized_text'], df['is_llm']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "CYRzmIjX740b"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SET_FRACTION, random_state=69, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "swKl3uu6740c"
      },
      "outputs": [],
      "source": [
        "train_dataset = TextDataset(X_train, y_train)\n",
        "test_dataset = TextDataset(X_test, y_test)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False, collate_fn=collate_fn)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXQtaoJu740c"
      },
      "source": [
        "## Train and test functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "GO-Re-58740d"
      },
      "outputs": [],
      "source": [
        "def calculate_accuracy(y_true, y_hat):\n",
        "    correct_pred = torch.eq(torch.sigmoid(y_hat).round(), y_true).sum().item()\n",
        "    return (correct_pred / len(y_hat)) * 100\n",
        "\n",
        "def calculate_f1(y_true, y_hat):\n",
        "    y_pred = torch.sigmoid(y_hat).round()\n",
        "    return f1_score(y_true, y_pred)\n",
        "\n",
        "def calculate_brier(y_true, y_hat):\n",
        "    y_prob = torch.sigmoid(y_hat)\n",
        "    return brier_score_loss(y_true, y_prob)\n",
        "\n",
        "def calculate_auc(y_true, y_hat):\n",
        "    y_prob = torch.sigmoid(y_hat)\n",
        "\n",
        "    false_positive_rates, true_positive_rates, _ = roc_curve(y_true, y_prob)\n",
        "    roc_auc = auc(false_positive_rates, true_positive_rates)\n",
        "\n",
        "    return roc_auc, false_positive_rates, true_positive_rates\n",
        "\n",
        "def train_step(model, dataloader, loss_fn, optimizer, device):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    train_loss, train_acc = 0, 0\n",
        "    steps = 0\n",
        "\n",
        "    for X, lengths, y in dataloader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        y_hat = model(X, lengths)\n",
        "\n",
        "        loss = loss_fn(y_hat, y)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_acc += calculate_accuracy(y_true=y, y_hat=y_hat)\n",
        "        steps += 1\n",
        "\n",
        "    return train_loss / steps, train_acc / steps\n",
        "\n",
        "\n",
        "def test_step(model, dataloader, loss_fn, device):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    all_y_true = []\n",
        "    all_y_hat = []\n",
        "\n",
        "    test_loss = 0\n",
        "    steps = 0\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for X, lengths, y in dataloader:\n",
        "\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            y_hat = model(X, lengths)\n",
        "\n",
        "            all_y_true.extend(y)\n",
        "            all_y_hat.extend(y_hat)\n",
        "\n",
        "            loss = loss_fn(y_hat, y)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            steps += 1\n",
        "\n",
        "        all_y_true = torch.FloatTensor(all_y_true)\n",
        "        all_y_hat = torch.FloatTensor(all_y_hat)\n",
        "\n",
        "        test_accuracy = calculate_accuracy(all_y_true, all_y_hat)\n",
        "        test_f1 = calculate_f1(all_y_true, all_y_hat)\n",
        "        test_brier = calculate_brier(all_y_true, all_y_hat)\n",
        "        test_auc_tuple = calculate_auc(all_y_true, all_y_hat)\n",
        "\n",
        "    return test_loss / steps, test_accuracy, test_f1, test_brier, test_auc_tuple\n",
        "\n",
        "def train(model,\n",
        "          train_dataloader,\n",
        "          test_dataloader,\n",
        "          optimizer,\n",
        "          loss_fn,\n",
        "          epochs,\n",
        "          device):\n",
        "\n",
        "    results = {\n",
        "        \"train_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"test_loss\": [],\n",
        "        \"test_acc\": [],\n",
        "        \"test_f1\": [],\n",
        "        \"test_brier\": [],\n",
        "        \"test_auc_tuple\": []\n",
        "    }\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "\n",
        "        start_time = timer()\n",
        "        train_loss, train_acc = train_step(\n",
        "            model=model,\n",
        "            dataloader=train_dataloader,\n",
        "            loss_fn=loss_fn,\n",
        "            optimizer=optimizer,\n",
        "            device=device,\n",
        "        )\n",
        "        end_time = timer()\n",
        "\n",
        "        test_loss, test_acc, test_f1, test_brier, test_auc_tuple = test_step(\n",
        "            model=model,\n",
        "            dataloader=test_dataloader,\n",
        "            loss_fn=loss_fn,\n",
        "            device=device,\n",
        "        )\n",
        "\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "        results[\"test_f1\"].append(test_f1)\n",
        "        results[\"test_brier\"].append(test_brier),\n",
        "        results[\"test_auc_tuple\"].append(test_auc_tuple)\n",
        "\n",
        "        save_path = os.path.join(MODELS_JSON_FOLDER_PATH, f'all_vs_all_epoch_{epoch}.pt')\n",
        "        torch.save(model.cpu().state_dict(), save_path) # change model to cpu in order to save it\n",
        "        model.to(device) # send model back to the device used\n",
        "\n",
        "        print(\n",
        "            f\"Epoch: {epoch+1} | \"\n",
        "            f\"train_loss: {train_loss:.4f} | \"\n",
        "            f\"train_acc: {train_acc:.4f} | \"\n",
        "            f\"test_loss: {test_loss:.4f} | \"\n",
        "            f\"test_acc: {test_acc:.4f} | \"\n",
        "            f\"test_f1: {test_f1:.4f} | \"\n",
        "            f\"test_brier: {test_brier:.4f} | \"\n",
        "            f\"time: {(end_time-start_time):.4f}\"\n",
        "        )\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh-AK_iL740e"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "0dHwAYtk740f"
      },
      "outputs": [],
      "source": [
        "model = RNN(tokenizer.vocab_size, EMBEDDING_SIZE, LSTM_UNITS, LSTM_LAYERS, device, dropout=0.6).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.00008)\n",
        "loss_fn = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijEtT3_Z740f",
        "outputId": "3d4a8447-1f49-4e86-d89c-475f248409c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 1/20 [01:50<35:03, 110.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.3009 | train_acc: 92.8558 | test_loss: 0.2243 | test_acc: 92.8603 | test_f1: 0.9630 | test_brier: 0.0599 | time: 96.2959\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 2/20 [03:43<33:38, 112.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2 | train_loss: 0.2125 | train_acc: 93.1065 | test_loss: 0.1377 | test_acc: 94.6124 | test_f1: 0.9715 | test_brier: 0.0394 | time: 98.6168\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 3/20 [05:35<31:41, 111.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3 | train_loss: 0.1201 | train_acc: 95.5518 | test_loss: 0.1124 | test_acc: 95.5103 | test_f1: 0.9757 | test_brier: 0.0327 | time: 97.0387\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 4/20 [07:26<29:43, 111.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 4 | train_loss: 0.0880 | train_acc: 96.9112 | test_loss: 0.0964 | test_acc: 95.9483 | test_f1: 0.9783 | test_brier: 0.0287 | time: 96.5036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 5/20 [09:15<27:41, 110.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 5 | train_loss: 0.0683 | train_acc: 97.7075 | test_loss: 0.0905 | test_acc: 96.2768 | test_f1: 0.9800 | test_brier: 0.0273 | time: 95.1633\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 6/20 [11:05<25:47, 110.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 6 | train_loss: 0.0482 | train_acc: 98.4690 | test_loss: 0.1137 | test_acc: 95.7074 | test_f1: 0.9772 | test_brier: 0.0325 | time: 95.3236\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 7/20 [12:55<23:55, 110.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 7 | train_loss: 0.0416 | train_acc: 98.6674 | test_loss: 0.0883 | test_acc: 96.6272 | test_f1: 0.9819 | test_brier: 0.0257 | time: 95.9111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 8/20 [14:45<22:01, 110.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 8 | train_loss: 0.0278 | train_acc: 99.1836 | test_loss: 0.1145 | test_acc: 96.0140 | test_f1: 0.9787 | test_brier: 0.0304 | time: 95.1578\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 9/20 [16:35<20:09, 109.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 9 | train_loss: 0.0274 | train_acc: 99.2680 | test_loss: 0.0963 | test_acc: 96.6710 | test_f1: 0.9820 | test_brier: 0.0265 | time: 95.2465\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 10/20 [18:25<18:20, 110.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 10 | train_loss: 0.0252 | train_acc: 99.3337 | test_loss: 0.0973 | test_acc: 96.4301 | test_f1: 0.9807 | test_brier: 0.0267 | time: 95.7295\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 11/20 [20:15<16:29, 109.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 11 | train_loss: 0.0203 | train_acc: 99.4262 | test_loss: 0.1014 | test_acc: 96.6929 | test_f1: 0.9821 | test_brier: 0.0259 | time: 95.2855\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 12/20 [22:04<14:37, 109.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 12 | train_loss: 0.0179 | train_acc: 99.4276 | test_loss: 0.1046 | test_acc: 96.6929 | test_f1: 0.9822 | test_brier: 0.0266 | time: 94.5635\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 13/20 [23:54<12:48, 109.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 13 | train_loss: 0.0121 | train_acc: 99.7185 | test_loss: 0.1061 | test_acc: 96.7587 | test_f1: 0.9826 | test_brier: 0.0257 | time: 95.6321\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 14/20 [25:43<10:58, 109.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 14 | train_loss: 0.0067 | train_acc: 99.8498 | test_loss: 0.1133 | test_acc: 96.6272 | test_f1: 0.9819 | test_brier: 0.0261 | time: 95.2709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 15/20 [27:33<09:09, 109.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 15 | train_loss: 0.0076 | train_acc: 99.8592 | test_loss: 0.1163 | test_acc: 96.6710 | test_f1: 0.9822 | test_brier: 0.0269 | time: 95.5389\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 16/20 [29:23<07:18, 109.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 16 | train_loss: 0.0052 | train_acc: 99.9236 | test_loss: 0.1202 | test_acc: 96.4520 | test_f1: 0.9809 | test_brier: 0.0277 | time: 95.2150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 85%|████████▌ | 17/20 [31:13<05:29, 109.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 17 | train_loss: 0.0232 | train_acc: 99.3056 | test_loss: 0.1076 | test_acc: 96.8463 | test_f1: 0.9831 | test_brier: 0.0254 | time: 95.2915\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 18/20 [33:02<03:39, 109.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 18 | train_loss: 0.0112 | train_acc: 99.8485 | test_loss: 0.1500 | test_acc: 96.2549 | test_f1: 0.9801 | test_brier: 0.0318 | time: 95.1456\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 95%|█████████▌| 19/20 [34:52<01:49, 109.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 19 | train_loss: 0.0142 | train_acc: 99.5871 | test_loss: 0.1232 | test_acc: 96.6053 | test_f1: 0.9818 | test_brier: 0.0284 | time: 95.5868\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [36:42<00:00, 110.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 20 | train_loss: 0.0076 | train_acc: 99.8123 | test_loss: 0.1258 | test_acc: 96.7806 | test_f1: 0.9827 | test_brier: 0.0273 | time: 95.2565\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "results = train(\n",
        "    model,\n",
        "    train_dataloader,\n",
        "    test_dataloader,\n",
        "    optimizer,\n",
        "    loss_fn,\n",
        "    epochs=20,\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xmcn_qFa740h"
      },
      "source": [
        "## Save results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "bbV8DyHF740h"
      },
      "outputs": [],
      "source": [
        "class json_serialize(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.integer):\n",
        "            return int(obj)\n",
        "        if isinstance(obj, np.floating):\n",
        "            return float(obj)\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        return json.JSONEncoder.default(self, obj)\n",
        "\n",
        "with open(f'{ROOT_DATA_RAW}/all_vs_all.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(results, f, ensure_ascii=False, indent=4, cls=json_serialize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEzoEYKPIlUT",
        "outputId": "475dd593-9b56-4ca7-8d16-e2fd899a4e91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: machines/ (stored 0%)\n",
            "  adding: machines/alpaca-7b.jsonl (deflated 73%)\n",
            "  adding: machines/all_vs_all_epoch_12.pt (deflated 8%)\n",
            "  adding: machines/all_vs_all_epoch_17.pt (deflated 8%)\n",
            "  adding: machines/bigscience-bloomz-7b1.jsonl (deflated 77%)\n",
            "  adding: machines/all_vs_all_epoch_5.pt (deflated 8%)\n",
            "  adding: machines/all_vs_all_epoch_1.pt (deflated 8%)\n",
            "  adding: machines/mistralai-mixtral-8x7b-instruct-v0.1.jsonl (deflated 69%)\n",
            "  adding: machines/all_vs_all_epoch_16.pt (deflated 8%)\n",
            "  adding: machines/gpt-3.5-turbo-0125.jsonl (deflated 69%)\n",
            "  adding: machines/chavinlo-alpaca-13b.jsonl (deflated 77%)\n",
            "  adding: machines/all_vs_all_epoch_14.pt (deflated 8%)\n",
            "  adding: machines/all_vs_all_epoch_7.pt (deflated 8%)\n",
            "  adding: machines/all_vs_all_epoch_4.pt (deflated 8%)\n",
            "  adding: machines/meta-llama-llama-2-7b-chat-hf.jsonl (deflated 72%)\n",
            "  adding: machines/all_vs_all_epoch_6.pt (deflated 8%)\n",
            "  adding: machines/text-bison-002.jsonl (deflated 70%)\n",
            "  adding: machines/gemini-pro.jsonl (deflated 70%)\n",
            "  adding: machines/vicgalle-gpt2-open-instruct-v1.jsonl (deflated 77%)\n",
            "  adding: machines/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: machines/all_vs_all_epoch_3.pt (deflated 8%)\n",
            "  adding: machines/gpt-4-turbo-preview.jsonl (deflated 68%)\n",
            "  adding: machines/all_vs_all_epoch_13.pt (deflated 8%)\n",
            "  adding: machines/all_vs_all_epoch_15.pt (deflated 8%)\n",
            "  adding: machines/mistralai-mistral-7b-instruct-v0.2.jsonl (deflated 70%)\n",
            "  adding: machines/all_vs_all_epoch_10.pt (deflated 8%)\n",
            "  adding: machines/all_vs_all_epoch_9.pt (deflated 8%)\n",
            "  adding: machines/all_vs_all_epoch_8.pt (deflated 8%)\n",
            "  adding: machines/all_vs_all_epoch_11.pt (deflated 8%)\n",
            "  adding: machines/qwen-qwen1.5-72b-chat-8bit.jsonl (deflated 69%)\n",
            "  adding: machines/all_vs_all_epoch_18.pt (deflated 7%)\n",
            "  adding: machines/all_vs_all_epoch_19.pt (deflated 8%)\n",
            "  adding: machines/all_vs_all_epoch_2.pt (deflated 8%)\n",
            "  adding: machines/meta-llama-llama-2-70b-chat-hf.jsonl (deflated 72%)\n",
            "  adding: machines/all_vs_all_epoch_0.pt (deflated 8%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r ./all_vs_all_model.zip ./machines/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChM4CWZJXXwo",
        "outputId": "b837e306-01ab-42e8-a391-d037bf1618b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLw1Oyo4X9d1",
        "outputId": "d80fb4d8-9054-4b8d-f380-5bbcbf230427"
      },
      "outputs": [],
      "source": [
        "!cp ./all_vs_all_model.zip '/content/gdrive/My Drive/'\n",
        "!ls -lt '/content/gdrive/My Drive/'"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
